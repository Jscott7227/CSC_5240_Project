{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "821ecb4d-9c2f-464a-9b94-9531b77825e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier  \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5b4d66c-c4ef-4331-a23c-28720d100baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5123abd1-7693-489f-8a25-952b77ca8911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>367.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>362.000000</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>338.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4805.599455</td>\n",
       "      <td>1569.577657</td>\n",
       "      <td>136.132597</td>\n",
       "      <td>342.537396</td>\n",
       "      <td>0.825444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4910.685399</td>\n",
       "      <td>2334.232099</td>\n",
       "      <td>61.366652</td>\n",
       "      <td>65.156643</td>\n",
       "      <td>0.380150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2864.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.250000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3786.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5060.000000</td>\n",
       "      <td>2430.500000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72529.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "count       367.000000         367.000000  362.000000        361.000000   \n",
       "mean       4805.599455        1569.577657  136.132597        342.537396   \n",
       "std        4910.685399        2334.232099   61.366652         65.156643   \n",
       "min           0.000000           0.000000   28.000000          6.000000   \n",
       "25%        2864.000000           0.000000  100.250000        360.000000   \n",
       "50%        3786.000000        1025.000000  125.000000        360.000000   \n",
       "75%        5060.000000        2430.500000  158.000000        360.000000   \n",
       "max       72529.000000       24000.000000  550.000000        480.000000   \n",
       "\n",
       "       Credit_History  \n",
       "count      338.000000  \n",
       "mean         0.825444  \n",
       "std          0.380150  \n",
       "min          0.000000  \n",
       "25%          1.000000  \n",
       "50%          1.000000  \n",
       "75%          1.000000  \n",
       "max          1.000000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a650b7e-e3e0-4701-a021-80271126b4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001015</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001022</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3076</td>\n",
       "      <td>1500</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001031</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5000</td>\n",
       "      <td>1800</td>\n",
       "      <td>208.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001035</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2340</td>\n",
       "      <td>2546</td>\n",
       "      <td>100.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001051</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3276</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>LP002971</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4009</td>\n",
       "      <td>1777</td>\n",
       "      <td>113.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>LP002975</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4158</td>\n",
       "      <td>709</td>\n",
       "      <td>115.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>LP002980</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3250</td>\n",
       "      <td>1993</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Semiurban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>LP002986</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5000</td>\n",
       "      <td>2393</td>\n",
       "      <td>158.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>LP002989</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0    LP001015   Male     Yes          0      Graduate            No   \n",
       "1    LP001022   Male     Yes          1      Graduate            No   \n",
       "2    LP001031   Male     Yes          2      Graduate            No   \n",
       "3    LP001035   Male     Yes          2      Graduate            No   \n",
       "4    LP001051   Male      No          0  Not Graduate            No   \n",
       "..        ...    ...     ...        ...           ...           ...   \n",
       "362  LP002971   Male     Yes         3+  Not Graduate           Yes   \n",
       "363  LP002975   Male     Yes          0      Graduate            No   \n",
       "364  LP002980   Male      No          0      Graduate            No   \n",
       "365  LP002986   Male     Yes          0      Graduate            No   \n",
       "366  LP002989   Male      No          0      Graduate           Yes   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0               5720                  0       110.0             360.0   \n",
       "1               3076               1500       126.0             360.0   \n",
       "2               5000               1800       208.0             360.0   \n",
       "3               2340               2546       100.0             360.0   \n",
       "4               3276                  0        78.0             360.0   \n",
       "..               ...                ...         ...               ...   \n",
       "362             4009               1777       113.0             360.0   \n",
       "363             4158                709       115.0             360.0   \n",
       "364             3250               1993       126.0             360.0   \n",
       "365             5000               2393       158.0             360.0   \n",
       "366             9200                  0        98.0             180.0   \n",
       "\n",
       "     Credit_History Property_Area  \n",
       "0               1.0         Urban  \n",
       "1               1.0         Urban  \n",
       "2               1.0         Urban  \n",
       "3               NaN         Urban  \n",
       "4               1.0         Urban  \n",
       "..              ...           ...  \n",
       "362             1.0         Urban  \n",
       "363             1.0         Urban  \n",
       "364             NaN     Semiurban  \n",
       "365             1.0         Rural  \n",
       "366             1.0         Rural  \n",
       "\n",
       "[367 rows x 12 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6cf3fcf8-8e33-4fff-96c7-5651a55831ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Gender'].fillna('Male', inplace=True) #We noticed that males were more common so we decide input with mode\n",
    "test['Gender'] = test['Gender'].map({'Male': 0, 'Female': 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4beb66a7-9bce-470f-8789-bca19c7cc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Gender'].fillna('Male', inplace=True)\n",
    "train['Gender'] = train['Gender'].map({'Male': 0, 'Female': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "765b6e02-8e6f-452c-aae2-7941d875f3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>is_Urban</th>\n",
       "      <th>is_Rural</th>\n",
       "      <th>is_Semiurban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001015</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001022</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3076</td>\n",
       "      <td>1500</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001031</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5000</td>\n",
       "      <td>1800</td>\n",
       "      <td>208.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001035</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2340</td>\n",
       "      <td>2546</td>\n",
       "      <td>100.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001051</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3276</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>LP002971</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4009</td>\n",
       "      <td>1777</td>\n",
       "      <td>113.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>LP002975</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4158</td>\n",
       "      <td>709</td>\n",
       "      <td>115.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>LP002980</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3250</td>\n",
       "      <td>1993</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>LP002986</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5000</td>\n",
       "      <td>2393</td>\n",
       "      <td>158.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>LP002989</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n",
       "0    LP001015       0     Yes          0      Graduate            No   \n",
       "1    LP001022       0     Yes          1      Graduate            No   \n",
       "2    LP001031       0     Yes          2      Graduate            No   \n",
       "3    LP001035       0     Yes          2      Graduate            No   \n",
       "4    LP001051       0      No          0  Not Graduate            No   \n",
       "..        ...     ...     ...        ...           ...           ...   \n",
       "362  LP002971       0     Yes         3+  Not Graduate           Yes   \n",
       "363  LP002975       0     Yes          0      Graduate            No   \n",
       "364  LP002980       0      No          0      Graduate            No   \n",
       "365  LP002986       0     Yes          0      Graduate            No   \n",
       "366  LP002989       0      No          0      Graduate           Yes   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0               5720                  0       110.0             360.0   \n",
       "1               3076               1500       126.0             360.0   \n",
       "2               5000               1800       208.0             360.0   \n",
       "3               2340               2546       100.0             360.0   \n",
       "4               3276                  0        78.0             360.0   \n",
       "..               ...                ...         ...               ...   \n",
       "362             4009               1777       113.0             360.0   \n",
       "363             4158                709       115.0             360.0   \n",
       "364             3250               1993       126.0             360.0   \n",
       "365             5000               2393       158.0             360.0   \n",
       "366             9200                  0        98.0             180.0   \n",
       "\n",
       "     Credit_History  is_Urban  is_Rural  is_Semiurban  \n",
       "0               1.0         1         0             0  \n",
       "1               1.0         1         0             0  \n",
       "2               1.0         1         0             0  \n",
       "3               NaN         1         0             0  \n",
       "4               1.0         1         0             0  \n",
       "..              ...       ...       ...           ...  \n",
       "362             1.0         1         0             0  \n",
       "363             1.0         1         0             0  \n",
       "364             NaN         0         0             1  \n",
       "365             1.0         0         1             0  \n",
       "366             1.0         0         1             0  \n",
       "\n",
       "[367 rows x 14 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['is_Urban'] = test['Property_Area'].map({'Urban': 1, 'Rural': 0, 'Semiurban':0})\n",
    "test['is_Rural'] = test['Property_Area'].map({'Urban': 0, 'Rural': 1, 'Semiurban':0})\n",
    "test['is_Semiurban'] = test['Property_Area'].map({'Urban': 0, 'Rural': 0, 'Semiurban':1})\n",
    "test.drop(['Property_Area'], axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7ea43e7-fff1-4ccb-b5a2-7ed88ec20412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>is_Urban</th>\n",
       "      <th>is_Rural</th>\n",
       "      <th>is_Semiurban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>LP002978</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>LP002979</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>LP002983</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>8072</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>LP002984</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>7583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>LP002990</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n",
       "0    LP001002       0      No          0      Graduate            No   \n",
       "1    LP001003       0     Yes          1      Graduate            No   \n",
       "2    LP001005       0     Yes          0      Graduate           Yes   \n",
       "3    LP001006       0     Yes          0  Not Graduate            No   \n",
       "4    LP001008       0      No          0      Graduate            No   \n",
       "..        ...     ...     ...        ...           ...           ...   \n",
       "609  LP002978       1      No          0      Graduate            No   \n",
       "610  LP002979       0     Yes         3+      Graduate            No   \n",
       "611  LP002983       0     Yes          1      Graduate            No   \n",
       "612  LP002984       0     Yes          2      Graduate            No   \n",
       "613  LP002990       1      No          0      Graduate           Yes   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0               5849                0.0         NaN             360.0   \n",
       "1               4583             1508.0       128.0             360.0   \n",
       "2               3000                0.0        66.0             360.0   \n",
       "3               2583             2358.0       120.0             360.0   \n",
       "4               6000                0.0       141.0             360.0   \n",
       "..               ...                ...         ...               ...   \n",
       "609             2900                0.0        71.0             360.0   \n",
       "610             4106                0.0        40.0             180.0   \n",
       "611             8072              240.0       253.0             360.0   \n",
       "612             7583                0.0       187.0             360.0   \n",
       "613             4583                0.0       133.0             360.0   \n",
       "\n",
       "     Credit_History Loan_Status  is_Urban  is_Rural  is_Semiurban  \n",
       "0               1.0           Y         1         0             0  \n",
       "1               1.0           N         0         1             0  \n",
       "2               1.0           Y         1         0             0  \n",
       "3               1.0           Y         1         0             0  \n",
       "4               1.0           Y         1         0             0  \n",
       "..              ...         ...       ...       ...           ...  \n",
       "609             1.0           Y         0         1             0  \n",
       "610             1.0           Y         0         1             0  \n",
       "611             1.0           Y         1         0             0  \n",
       "612             1.0           Y         1         0             0  \n",
       "613             0.0           N         0         0             1  \n",
       "\n",
       "[614 rows x 15 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['is_Urban'] = train['Property_Area'].map({'Urban': 1, 'Rural': 0, 'Semiurban':0})\n",
    "train['is_Rural'] = train['Property_Area'].map({'Urban': 0, 'Rural': 1, 'Semiurban':0})\n",
    "train['is_Semiurban'] = train['Property_Area'].map({'Urban': 0, 'Rural': 0, 'Semiurban':1})\n",
    "train.drop(['Property_Area'], axis = 1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2ec974c2-3e22-401a-ae03-1838e63f8a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_Married = train['Married'].mode()[0]\n",
    "train['Married'].fillna(mode_Married, inplace=True)\n",
    "train['Married'] = train['Married'].map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "95f8d4ea-c2b6-4c0e-aec7-38b20c9a5340",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Married'] = test['Married'].map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b09abdb-c60d-442a-b224-805a1567972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Dependents'].fillna(0, inplace=True)\n",
    "train['Dependents'] = train['Dependents'].replace('3+', '3')\n",
    "train['Dependents'] = pd.to_numeric(train['Dependents'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4a4f63d-cced-4470-b579-b324ebc7b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Dependents'].fillna(0, inplace=True)\n",
    "test['Dependents'] = test['Dependents'].replace('3+', '3')\n",
    "test['Dependents'] = pd.to_numeric(test['Dependents'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e36040d2-2359-4e0b-a85e-32a2ffaddb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Education'] = train['Education'].map({'Not Graduate': 0, 'Graduate': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ff03bf85-de48-41e4-af64-99c05ebe0161",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Education'] = test['Education'].map({'Not Graduate': 0, 'Graduate': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f0158ab8-f569-4e08-816c-c0deea05e2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_SE = test['Self_Employed'].mode()[0]\n",
    "test['Self_Employed'].fillna(mode_SE, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "df69abe1-c353-459b-acde-197a0b539ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Self_Employed'] = test['Self_Employed'].map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "be914b8a-d66b-4b6c-b261-817fb085ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_SE = train['Self_Employed'].mode()[0]\n",
    "train['Self_Employed'].fillna(mode_SE, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8d6b2531-2e11-463c-82ea-4a0f8004e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Self_Employed'] = train['Self_Employed'].map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "03a8d710-46e5-49ad-9e02-b82e3206e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_LoanAmount = test['LoanAmount'].mean()\n",
    "test['LoanAmount'].fillna(round(mean_LoanAmount,1), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "66223324-daa4-45f9-8221-c26b70d423c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_LoanAmount = train['LoanAmount'].mean()\n",
    "train['LoanAmount'].fillna(round(mean_LoanAmount,1), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3d062304-01b8-4cd9-af82-5755941ab7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_Term = test['Loan_Amount_Term'].mode()[0]\n",
    "test['Loan_Amount_Term'].fillna(mode_Term, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "544a5882-8457-4015-b3a6-614d61561154",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_Term = train['Loan_Amount_Term'].mode()[0]\n",
    "train['Loan_Amount_Term'].fillna(mode_Term, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0a8ff80c-bb73-42f4-8807-3c3de3ef8030",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_Credit = train['Credit_History'].mode()[0]\n",
    "train['Credit_History'].fillna(mode_Credit, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "28d6ab75-fe3e-46ed-8a3e-c7cd1bf89953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>is_Urban</th>\n",
       "      <th>is_Rural</th>\n",
       "      <th>is_Semiurban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.4</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>LP002978</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>LP002979</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>LP002983</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8072</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>LP002984</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>LP002990</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID  Gender  Married  Dependents  Education  Self_Employed  \\\n",
       "0    LP001002       0        0           0          1              0   \n",
       "1    LP001003       0        1           1          1              0   \n",
       "2    LP001005       0        1           0          1              1   \n",
       "3    LP001006       0        1           0          0              0   \n",
       "4    LP001008       0        0           0          1              0   \n",
       "..        ...     ...      ...         ...        ...            ...   \n",
       "609  LP002978       1        0           0          1              0   \n",
       "610  LP002979       0        1           3          1              0   \n",
       "611  LP002983       0        1           1          1              0   \n",
       "612  LP002984       0        1           2          1              0   \n",
       "613  LP002990       1        0           0          1              1   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0               5849                0.0       146.4             360.0   \n",
       "1               4583             1508.0       128.0             360.0   \n",
       "2               3000                0.0        66.0             360.0   \n",
       "3               2583             2358.0       120.0             360.0   \n",
       "4               6000                0.0       141.0             360.0   \n",
       "..               ...                ...         ...               ...   \n",
       "609             2900                0.0        71.0             360.0   \n",
       "610             4106                0.0        40.0             180.0   \n",
       "611             8072              240.0       253.0             360.0   \n",
       "612             7583                0.0       187.0             360.0   \n",
       "613             4583                0.0       133.0             360.0   \n",
       "\n",
       "     Credit_History Property_Area Loan_Status  is_Urban  is_Rural  \\\n",
       "0               1.0         Urban           Y         1         0   \n",
       "1               1.0         Rural           N         0         1   \n",
       "2               1.0         Urban           Y         1         0   \n",
       "3               1.0         Urban           Y         1         0   \n",
       "4               1.0         Urban           Y         1         0   \n",
       "..              ...           ...         ...       ...       ...   \n",
       "609             1.0         Rural           Y         0         1   \n",
       "610             1.0         Rural           Y         0         1   \n",
       "611             1.0         Urban           Y         1         0   \n",
       "612             1.0         Urban           Y         1         0   \n",
       "613             0.0     Semiurban           N         0         0   \n",
       "\n",
       "     is_Semiurban  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "609             0  \n",
       "610             0  \n",
       "611             0  \n",
       "612             0  \n",
       "613             1  \n",
       "\n",
       "[614 rows x 16 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "036189b3-9008-4949-b83d-2c2c2ec109ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>is_Urban</th>\n",
       "      <th>is_Rural</th>\n",
       "      <th>is_Semiurban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.4</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>LP002978</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>LP002979</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>LP002983</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8072</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>LP002984</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>LP002990</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID  Gender  Married  Dependents  Education  Self_Employed  \\\n",
       "0    LP001002       0        0           0          1              0   \n",
       "1    LP001003       0        1           1          1              0   \n",
       "2    LP001005       0        1           0          1              1   \n",
       "3    LP001006       0        1           0          0              0   \n",
       "4    LP001008       0        0           0          1              0   \n",
       "..        ...     ...      ...         ...        ...            ...   \n",
       "609  LP002978       1        0           0          1              0   \n",
       "610  LP002979       0        1           3          1              0   \n",
       "611  LP002983       0        1           1          1              0   \n",
       "612  LP002984       0        1           2          1              0   \n",
       "613  LP002990       1        0           0          1              1   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0               5849                0.0       146.4             360.0   \n",
       "1               4583             1508.0       128.0             360.0   \n",
       "2               3000                0.0        66.0             360.0   \n",
       "3               2583             2358.0       120.0             360.0   \n",
       "4               6000                0.0       141.0             360.0   \n",
       "..               ...                ...         ...               ...   \n",
       "609             2900                0.0        71.0             360.0   \n",
       "610             4106                0.0        40.0             180.0   \n",
       "611             8072              240.0       253.0             360.0   \n",
       "612             7583                0.0       187.0             360.0   \n",
       "613             4583                0.0       133.0             360.0   \n",
       "\n",
       "     Credit_History Loan_Status  is_Urban  is_Rural  is_Semiurban  \n",
       "0               1.0           Y         1         0             0  \n",
       "1               1.0           N         0         1             0  \n",
       "2               1.0           Y         1         0             0  \n",
       "3               1.0           Y         1         0             0  \n",
       "4               1.0           Y         1         0             0  \n",
       "..              ...         ...       ...       ...           ...  \n",
       "609             1.0           Y         0         1             0  \n",
       "610             1.0           Y         0         1             0  \n",
       "611             1.0           Y         1         0             0  \n",
       "612             1.0           Y         1         0             0  \n",
       "613             0.0           N         0         0             1  \n",
       "\n",
       "[614 rows x 15 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop(['Property_Area'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bfea3cb8-573a-43c1-8eb8-88f8f8c6a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Loan_Status'] = train['Loan_Status'].map({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ea653a34-e693-47e7-b1d3-f63f16f37438",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = train.drop(['Loan_ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "61070ed2-4f3c-48c6-b31b-642b5a46f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean\n",
    "train_clean = train_clean.drop(['Property_Area'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0fba0134-f893-4ea5-8d7c-a40f1c1a7ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_clean.drop(['Loan_Status'], axis = 1)\n",
    "Y = train_clean['Loan_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1f038619-fb88-4e67-b33d-56cb9bb8efd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f427bc85-a414-44c9-9496-2c8c5425f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4e3fd4fc-3ef5-4ea0-a024-d8938bd2d0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f264e232-994e-40f0-8ad6-aa974003a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=200, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=42,tol=0.000000001,\n",
    "                     early_stopping = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f2ea895c-1a26-4015-9916-c08741d56d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.74837942\n",
      "Validation score: 0.325000\n",
      "Iteration 2, loss = 0.74530302\n",
      "Validation score: 0.350000\n",
      "Iteration 3, loss = 0.74049636\n",
      "Validation score: 0.375000\n",
      "Iteration 4, loss = 0.73486495\n",
      "Validation score: 0.375000\n",
      "Iteration 5, loss = 0.72825791\n",
      "Validation score: 0.450000\n",
      "Iteration 6, loss = 0.72130434\n",
      "Validation score: 0.525000\n",
      "Iteration 7, loss = 0.71380153\n",
      "Validation score: 0.525000\n",
      "Iteration 8, loss = 0.70663969\n",
      "Validation score: 0.525000\n",
      "Iteration 9, loss = 0.69981121\n",
      "Validation score: 0.550000\n",
      "Iteration 10, loss = 0.69264569\n",
      "Validation score: 0.500000\n",
      "Iteration 11, loss = 0.68606363\n",
      "Validation score: 0.575000\n",
      "Iteration 12, loss = 0.67936676\n",
      "Validation score: 0.600000\n",
      "Iteration 13, loss = 0.67347767\n",
      "Validation score: 0.625000\n",
      "Iteration 14, loss = 0.66802525\n",
      "Validation score: 0.550000\n",
      "Iteration 15, loss = 0.66239910\n",
      "Validation score: 0.650000\n",
      "Iteration 16, loss = 0.65814462\n",
      "Validation score: 0.650000\n",
      "Iteration 17, loss = 0.65301724\n",
      "Validation score: 0.675000\n",
      "Iteration 18, loss = 0.64904017\n",
      "Validation score: 0.675000\n",
      "Iteration 19, loss = 0.64488750\n",
      "Validation score: 0.700000\n",
      "Iteration 20, loss = 0.64128751\n",
      "Validation score: 0.700000\n",
      "Iteration 21, loss = 0.63810874\n",
      "Validation score: 0.700000\n",
      "Iteration 22, loss = 0.63485555\n",
      "Validation score: 0.700000\n",
      "Iteration 23, loss = 0.63206480\n",
      "Validation score: 0.700000\n",
      "Iteration 24, loss = 0.62936760\n",
      "Validation score: 0.700000\n",
      "Iteration 25, loss = 0.62688021\n",
      "Validation score: 0.700000\n",
      "Iteration 26, loss = 0.62437793\n",
      "Validation score: 0.700000\n",
      "Iteration 27, loss = 0.62232104\n",
      "Validation score: 0.700000\n",
      "Iteration 28, loss = 0.62005117\n",
      "Validation score: 0.700000\n",
      "Iteration 29, loss = 0.61822947\n",
      "Validation score: 0.700000\n",
      "Iteration 30, loss = 0.61662099\n",
      "Validation score: 0.700000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74669255\n",
      "Validation score: 0.375000\n",
      "Iteration 2, loss = 0.74366242\n",
      "Validation score: 0.400000\n",
      "Iteration 3, loss = 0.73907673\n",
      "Validation score: 0.400000\n",
      "Iteration 4, loss = 0.73345258\n",
      "Validation score: 0.400000\n",
      "Iteration 5, loss = 0.72706138\n",
      "Validation score: 0.400000\n",
      "Iteration 6, loss = 0.72024414\n",
      "Validation score: 0.400000\n",
      "Iteration 7, loss = 0.71261100\n",
      "Validation score: 0.500000\n",
      "Iteration 8, loss = 0.70634134\n",
      "Validation score: 0.525000\n",
      "Iteration 9, loss = 0.69896083\n",
      "Validation score: 0.575000\n",
      "Iteration 10, loss = 0.69220055\n",
      "Validation score: 0.550000\n",
      "Iteration 11, loss = 0.68582233\n",
      "Validation score: 0.600000\n",
      "Iteration 12, loss = 0.67961621\n",
      "Validation score: 0.675000\n",
      "Iteration 13, loss = 0.67362660\n",
      "Validation score: 0.625000\n",
      "Iteration 14, loss = 0.66796840\n",
      "Validation score: 0.550000\n",
      "Iteration 15, loss = 0.66265366\n",
      "Validation score: 0.575000\n",
      "Iteration 16, loss = 0.65819944\n",
      "Validation score: 0.625000\n",
      "Iteration 17, loss = 0.65354069\n",
      "Validation score: 0.675000\n",
      "Iteration 18, loss = 0.64940825\n",
      "Validation score: 0.675000\n",
      "Iteration 19, loss = 0.64571132\n",
      "Validation score: 0.700000\n",
      "Iteration 20, loss = 0.64180889\n",
      "Validation score: 0.700000\n",
      "Iteration 21, loss = 0.63867789\n",
      "Validation score: 0.700000\n",
      "Iteration 22, loss = 0.63553026\n",
      "Validation score: 0.700000\n",
      "Iteration 23, loss = 0.63279631\n",
      "Validation score: 0.700000\n",
      "Iteration 24, loss = 0.62999391\n",
      "Validation score: 0.700000\n",
      "Iteration 25, loss = 0.62749121\n",
      "Validation score: 0.700000\n",
      "Iteration 26, loss = 0.62520262\n",
      "Validation score: 0.700000\n",
      "Iteration 27, loss = 0.62311796\n",
      "Validation score: 0.700000\n",
      "Iteration 28, loss = 0.62093797\n",
      "Validation score: 0.700000\n",
      "Iteration 29, loss = 0.61888938\n",
      "Validation score: 0.700000\n",
      "Iteration 30, loss = 0.61716432\n",
      "Validation score: 0.700000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74939828\n",
      "Validation score: 0.375000\n",
      "Iteration 2, loss = 0.74624605\n",
      "Validation score: 0.375000\n",
      "Iteration 3, loss = 0.74147765\n",
      "Validation score: 0.375000\n",
      "Iteration 4, loss = 0.73567609\n",
      "Validation score: 0.375000\n",
      "Iteration 5, loss = 0.72901310\n",
      "Validation score: 0.375000\n",
      "Iteration 6, loss = 0.72195238\n",
      "Validation score: 0.375000\n",
      "Iteration 7, loss = 0.71408335\n",
      "Validation score: 0.400000\n",
      "Iteration 8, loss = 0.70750897\n",
      "Validation score: 0.450000\n",
      "Iteration 9, loss = 0.69986272\n",
      "Validation score: 0.525000\n",
      "Iteration 10, loss = 0.69274288\n",
      "Validation score: 0.525000\n",
      "Iteration 11, loss = 0.68615268\n",
      "Validation score: 0.575000\n",
      "Iteration 12, loss = 0.67970522\n",
      "Validation score: 0.575000\n",
      "Iteration 13, loss = 0.67344505\n",
      "Validation score: 0.575000\n",
      "Iteration 14, loss = 0.66754928\n",
      "Validation score: 0.550000\n",
      "Iteration 15, loss = 0.66199938\n",
      "Validation score: 0.525000\n",
      "Iteration 16, loss = 0.65736223\n",
      "Validation score: 0.625000\n",
      "Iteration 17, loss = 0.65238435\n",
      "Validation score: 0.700000\n",
      "Iteration 18, loss = 0.64811097\n",
      "Validation score: 0.700000\n",
      "Iteration 19, loss = 0.64418438\n",
      "Validation score: 0.700000\n",
      "Iteration 20, loss = 0.64013719\n",
      "Validation score: 0.700000\n",
      "Iteration 21, loss = 0.63680194\n",
      "Validation score: 0.700000\n",
      "Iteration 22, loss = 0.63350155\n",
      "Validation score: 0.700000\n",
      "Iteration 23, loss = 0.63061147\n",
      "Validation score: 0.700000\n",
      "Iteration 24, loss = 0.62766137\n",
      "Validation score: 0.700000\n",
      "Iteration 25, loss = 0.62503411\n",
      "Validation score: 0.700000\n",
      "Iteration 26, loss = 0.62263577\n",
      "Validation score: 0.700000\n",
      "Iteration 27, loss = 0.62037081\n",
      "Validation score: 0.700000\n",
      "Iteration 28, loss = 0.61810526\n",
      "Validation score: 0.700000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74918484\n",
      "Validation score: 0.375000\n",
      "Iteration 2, loss = 0.74608594\n",
      "Validation score: 0.350000\n",
      "Iteration 3, loss = 0.74145105\n",
      "Validation score: 0.350000\n",
      "Iteration 4, loss = 0.73573150\n",
      "Validation score: 0.350000\n",
      "Iteration 5, loss = 0.72925509\n",
      "Validation score: 0.375000\n",
      "Iteration 6, loss = 0.72231420\n",
      "Validation score: 0.400000\n",
      "Iteration 7, loss = 0.71467644\n",
      "Validation score: 0.425000\n",
      "Iteration 8, loss = 0.70822246\n",
      "Validation score: 0.475000\n",
      "Iteration 9, loss = 0.70071507\n",
      "Validation score: 0.600000\n",
      "Iteration 10, loss = 0.69377359\n",
      "Validation score: 0.600000\n",
      "Iteration 11, loss = 0.68733444\n",
      "Validation score: 0.625000\n",
      "Iteration 12, loss = 0.68100631\n",
      "Validation score: 0.675000\n",
      "Iteration 13, loss = 0.67487492\n",
      "Validation score: 0.650000\n",
      "Iteration 14, loss = 0.66907017\n",
      "Validation score: 0.600000\n",
      "Iteration 15, loss = 0.66355701\n",
      "Validation score: 0.600000\n",
      "Iteration 16, loss = 0.65896138\n",
      "Validation score: 0.650000\n",
      "Iteration 17, loss = 0.65404175\n",
      "Validation score: 0.650000\n",
      "Iteration 18, loss = 0.64974791\n",
      "Validation score: 0.675000\n",
      "Iteration 19, loss = 0.64580650\n",
      "Validation score: 0.675000\n",
      "Iteration 20, loss = 0.64175821\n",
      "Validation score: 0.700000\n",
      "Iteration 21, loss = 0.63839453\n",
      "Validation score: 0.700000\n",
      "Iteration 22, loss = 0.63503849\n",
      "Validation score: 0.700000\n",
      "Iteration 23, loss = 0.63209656\n",
      "Validation score: 0.700000\n",
      "Iteration 24, loss = 0.62910962\n",
      "Validation score: 0.700000\n",
      "Iteration 25, loss = 0.62640770\n",
      "Validation score: 0.700000\n",
      "Iteration 26, loss = 0.62391073\n",
      "Validation score: 0.700000\n",
      "Iteration 27, loss = 0.62160922\n",
      "Validation score: 0.700000\n",
      "Iteration 28, loss = 0.61920570\n",
      "Validation score: 0.700000\n",
      "Iteration 29, loss = 0.61696498\n",
      "Validation score: 0.700000\n",
      "Iteration 30, loss = 0.61499765\n",
      "Validation score: 0.700000\n",
      "Iteration 31, loss = 0.61306541\n",
      "Validation score: 0.700000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74868728\n",
      "Validation score: 0.350000\n",
      "Iteration 2, loss = 0.74559099\n",
      "Validation score: 0.325000\n",
      "Iteration 3, loss = 0.74096518\n",
      "Validation score: 0.325000\n",
      "Iteration 4, loss = 0.73533469\n",
      "Validation score: 0.325000\n",
      "Iteration 5, loss = 0.72888933\n",
      "Validation score: 0.350000\n",
      "Iteration 6, loss = 0.72181780\n",
      "Validation score: 0.375000\n",
      "Iteration 7, loss = 0.71484554\n",
      "Validation score: 0.425000\n",
      "Iteration 8, loss = 0.70738103\n",
      "Validation score: 0.475000\n",
      "Iteration 9, loss = 0.70024245\n",
      "Validation score: 0.525000\n",
      "Iteration 10, loss = 0.69354085\n",
      "Validation score: 0.575000\n",
      "Iteration 11, loss = 0.68672728\n",
      "Validation score: 0.625000\n",
      "Iteration 12, loss = 0.68045258\n",
      "Validation score: 0.625000\n",
      "Iteration 13, loss = 0.67445413\n",
      "Validation score: 0.600000\n",
      "Iteration 14, loss = 0.66879786\n",
      "Validation score: 0.625000\n",
      "Iteration 15, loss = 0.66340101\n",
      "Validation score: 0.625000\n",
      "Iteration 16, loss = 0.65865390\n",
      "Validation score: 0.650000\n",
      "Iteration 17, loss = 0.65406137\n",
      "Validation score: 0.650000\n",
      "Iteration 18, loss = 0.64969667\n",
      "Validation score: 0.650000\n",
      "Iteration 19, loss = 0.64575565\n",
      "Validation score: 0.675000\n",
      "Iteration 20, loss = 0.64197764\n",
      "Validation score: 0.675000\n",
      "Iteration 21, loss = 0.63847494\n",
      "Validation score: 0.700000\n",
      "Iteration 22, loss = 0.63540278\n",
      "Validation score: 0.700000\n",
      "Iteration 23, loss = 0.63224355\n",
      "Validation score: 0.700000\n",
      "Iteration 24, loss = 0.62962942\n",
      "Validation score: 0.700000\n",
      "Iteration 25, loss = 0.62707268\n",
      "Validation score: 0.700000\n",
      "Iteration 26, loss = 0.62451534\n",
      "Validation score: 0.700000\n",
      "Iteration 27, loss = 0.62197658\n",
      "Validation score: 0.700000\n",
      "Iteration 28, loss = 0.61992837\n",
      "Validation score: 0.700000\n",
      "Iteration 29, loss = 0.61785355\n",
      "Validation score: 0.700000\n",
      "Iteration 30, loss = 0.61605448\n",
      "Validation score: 0.700000\n",
      "Iteration 31, loss = 0.61419033\n",
      "Validation score: 0.700000\n",
      "Iteration 32, loss = 0.61222112\n",
      "Validation score: 0.700000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74409285\n",
      "Validation score: 0.425000\n",
      "Iteration 2, loss = 0.71640394\n",
      "Validation score: 0.525000\n",
      "Iteration 3, loss = 0.68137472\n",
      "Validation score: 0.650000\n",
      "Iteration 4, loss = 0.65218807\n",
      "Validation score: 0.700000\n",
      "Iteration 5, loss = 0.62836119\n",
      "Validation score: 0.700000\n",
      "Iteration 6, loss = 0.61321645\n",
      "Validation score: 0.700000\n",
      "Iteration 7, loss = 0.60311520\n",
      "Validation score: 0.700000\n",
      "Iteration 8, loss = 0.59747699\n",
      "Validation score: 0.700000\n",
      "Iteration 9, loss = 0.59388349\n",
      "Validation score: 0.700000\n",
      "Iteration 10, loss = 0.58823059\n",
      "Validation score: 0.700000\n",
      "Iteration 11, loss = 0.58203357\n",
      "Validation score: 0.700000\n",
      "Iteration 12, loss = 0.57436583\n",
      "Validation score: 0.700000\n",
      "Iteration 13, loss = 0.56590923\n",
      "Validation score: 0.700000\n",
      "Iteration 14, loss = 0.55732525\n",
      "Validation score: 0.750000\n",
      "Iteration 15, loss = 0.55011308\n",
      "Validation score: 0.775000\n",
      "Iteration 16, loss = 0.54120827\n",
      "Validation score: 0.800000\n",
      "Iteration 17, loss = 0.53480772\n",
      "Validation score: 0.825000\n",
      "Iteration 18, loss = 0.52780890\n",
      "Validation score: 0.825000\n",
      "Iteration 19, loss = 0.52191398\n",
      "Validation score: 0.825000\n",
      "Iteration 20, loss = 0.51524317\n",
      "Validation score: 0.825000\n",
      "Iteration 21, loss = 0.50897657\n",
      "Validation score: 0.800000\n",
      "Iteration 22, loss = 0.50286478\n",
      "Validation score: 0.800000\n",
      "Iteration 23, loss = 0.49700052\n",
      "Validation score: 0.800000\n",
      "Iteration 24, loss = 0.49128030\n",
      "Validation score: 0.800000\n",
      "Iteration 25, loss = 0.48591793\n",
      "Validation score: 0.800000\n",
      "Iteration 26, loss = 0.48066698\n",
      "Validation score: 0.800000\n",
      "Iteration 27, loss = 0.47602899\n",
      "Validation score: 0.800000\n",
      "Iteration 28, loss = 0.47159078\n",
      "Validation score: 0.800000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74250925\n",
      "Validation score: 0.400000\n",
      "Iteration 2, loss = 0.71522438\n",
      "Validation score: 0.550000\n",
      "Iteration 3, loss = 0.68181314\n",
      "Validation score: 0.600000\n",
      "Iteration 4, loss = 0.65194366\n",
      "Validation score: 0.700000\n",
      "Iteration 5, loss = 0.62900749\n",
      "Validation score: 0.700000\n",
      "Iteration 6, loss = 0.61370701\n",
      "Validation score: 0.700000\n",
      "Iteration 7, loss = 0.60223034\n",
      "Validation score: 0.700000\n",
      "Iteration 8, loss = 0.59909391\n",
      "Validation score: 0.700000\n",
      "Iteration 9, loss = 0.59290580\n",
      "Validation score: 0.700000\n",
      "Iteration 10, loss = 0.58697749\n",
      "Validation score: 0.700000\n",
      "Iteration 11, loss = 0.58036176\n",
      "Validation score: 0.700000\n",
      "Iteration 12, loss = 0.57161070\n",
      "Validation score: 0.700000\n",
      "Iteration 13, loss = 0.56219002\n",
      "Validation score: 0.700000\n",
      "Iteration 14, loss = 0.55249796\n",
      "Validation score: 0.750000\n",
      "Iteration 15, loss = 0.54384473\n",
      "Validation score: 0.750000\n",
      "Iteration 16, loss = 0.53472804\n",
      "Validation score: 0.775000\n",
      "Iteration 17, loss = 0.52707057\n",
      "Validation score: 0.825000\n",
      "Iteration 18, loss = 0.51948907\n",
      "Validation score: 0.825000\n",
      "Iteration 19, loss = 0.51174110\n",
      "Validation score: 0.850000\n",
      "Iteration 20, loss = 0.50496345\n",
      "Validation score: 0.850000\n",
      "Iteration 21, loss = 0.49757632\n",
      "Validation score: 0.850000\n",
      "Iteration 22, loss = 0.49026279\n",
      "Validation score: 0.850000\n",
      "Iteration 23, loss = 0.48381465\n",
      "Validation score: 0.850000\n",
      "Iteration 24, loss = 0.47652604\n",
      "Validation score: 0.850000\n",
      "Iteration 25, loss = 0.47038767\n",
      "Validation score: 0.850000\n",
      "Iteration 26, loss = 0.46478407\n",
      "Validation score: 0.850000\n",
      "Iteration 27, loss = 0.45981761\n",
      "Validation score: 0.850000\n",
      "Iteration 28, loss = 0.45478449\n",
      "Validation score: 0.850000\n",
      "Iteration 29, loss = 0.45047940\n",
      "Validation score: 0.850000\n",
      "Iteration 30, loss = 0.44619437\n",
      "Validation score: 0.850000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74509619\n",
      "Validation score: 0.375000\n",
      "Iteration 2, loss = 0.71673360\n",
      "Validation score: 0.525000\n",
      "Iteration 3, loss = 0.68193460\n",
      "Validation score: 0.600000\n",
      "Iteration 4, loss = 0.65088820\n",
      "Validation score: 0.700000\n",
      "Iteration 5, loss = 0.62674452\n",
      "Validation score: 0.700000\n",
      "Iteration 6, loss = 0.61026535\n",
      "Validation score: 0.700000\n",
      "Iteration 7, loss = 0.59835784\n",
      "Validation score: 0.700000\n",
      "Iteration 8, loss = 0.59462711\n",
      "Validation score: 0.700000\n",
      "Iteration 9, loss = 0.58830140\n",
      "Validation score: 0.700000\n",
      "Iteration 10, loss = 0.58217464\n",
      "Validation score: 0.700000\n",
      "Iteration 11, loss = 0.57579168\n",
      "Validation score: 0.700000\n",
      "Iteration 12, loss = 0.56698232\n",
      "Validation score: 0.700000\n",
      "Iteration 13, loss = 0.55731494\n",
      "Validation score: 0.700000\n",
      "Iteration 14, loss = 0.54743463\n",
      "Validation score: 0.700000\n",
      "Iteration 15, loss = 0.53861023\n",
      "Validation score: 0.675000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74499003\n",
      "Validation score: 0.375000\n",
      "Iteration 2, loss = 0.71713128\n",
      "Validation score: 0.600000\n",
      "Iteration 3, loss = 0.68338367\n",
      "Validation score: 0.600000\n",
      "Iteration 4, loss = 0.65258358\n",
      "Validation score: 0.700000\n",
      "Iteration 5, loss = 0.62878052\n",
      "Validation score: 0.700000\n",
      "Iteration 6, loss = 0.61155778\n",
      "Validation score: 0.700000\n",
      "Iteration 7, loss = 0.59880027\n",
      "Validation score: 0.700000\n",
      "Iteration 8, loss = 0.59371940\n",
      "Validation score: 0.700000\n",
      "Iteration 9, loss = 0.58558176\n",
      "Validation score: 0.700000\n",
      "Iteration 10, loss = 0.57810004\n",
      "Validation score: 0.700000\n",
      "Iteration 11, loss = 0.56924565\n",
      "Validation score: 0.700000\n",
      "Iteration 12, loss = 0.55867791\n",
      "Validation score: 0.700000\n",
      "Iteration 13, loss = 0.54699874\n",
      "Validation score: 0.700000\n",
      "Iteration 14, loss = 0.53617557\n",
      "Validation score: 0.675000\n",
      "Iteration 15, loss = 0.52579475\n",
      "Validation score: 0.725000\n",
      "Iteration 16, loss = 0.51482091\n",
      "Validation score: 0.750000\n",
      "Iteration 17, loss = 0.50565123\n",
      "Validation score: 0.725000\n",
      "Iteration 18, loss = 0.49639328\n",
      "Validation score: 0.750000\n",
      "Iteration 19, loss = 0.48738893\n",
      "Validation score: 0.750000\n",
      "Iteration 20, loss = 0.47921101\n",
      "Validation score: 0.750000\n",
      "Iteration 21, loss = 0.47040381\n",
      "Validation score: 0.750000\n",
      "Iteration 22, loss = 0.46204826\n",
      "Validation score: 0.750000\n",
      "Iteration 23, loss = 0.45454408\n",
      "Validation score: 0.750000\n",
      "Iteration 24, loss = 0.44671420\n",
      "Validation score: 0.750000\n",
      "Iteration 25, loss = 0.44024222\n",
      "Validation score: 0.750000\n",
      "Iteration 26, loss = 0.43452669\n",
      "Validation score: 0.750000\n",
      "Iteration 27, loss = 0.42949423\n",
      "Validation score: 0.750000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.74444320\n",
      "Validation score: 0.350000\n",
      "Iteration 2, loss = 0.71640413\n",
      "Validation score: 0.550000\n",
      "Iteration 3, loss = 0.68233013\n",
      "Validation score: 0.625000\n",
      "Iteration 4, loss = 0.65222577\n",
      "Validation score: 0.700000\n",
      "Iteration 5, loss = 0.62861264\n",
      "Validation score: 0.700000\n",
      "Iteration 6, loss = 0.61157674\n",
      "Validation score: 0.700000\n",
      "Iteration 7, loss = 0.60242958\n",
      "Validation score: 0.700000\n",
      "Iteration 8, loss = 0.59486043\n",
      "Validation score: 0.700000\n",
      "Iteration 9, loss = 0.58944135\n",
      "Validation score: 0.700000\n",
      "Iteration 10, loss = 0.58324916\n",
      "Validation score: 0.700000\n",
      "Iteration 11, loss = 0.57564370\n",
      "Validation score: 0.700000\n",
      "Iteration 12, loss = 0.56637523\n",
      "Validation score: 0.700000\n",
      "Iteration 13, loss = 0.55643482\n",
      "Validation score: 0.700000\n",
      "Iteration 14, loss = 0.54650174\n",
      "Validation score: 0.700000\n",
      "Iteration 15, loss = 0.53695617\n",
      "Validation score: 0.700000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71001273\n",
      "Validation score: 0.700000\n",
      "Iteration 2, loss = 0.61052113\n",
      "Validation score: 0.700000\n",
      "Iteration 3, loss = 0.59026723\n",
      "Validation score: 0.700000\n",
      "Iteration 4, loss = 0.55054833\n",
      "Validation score: 0.825000\n",
      "Iteration 5, loss = 0.50912457\n",
      "Validation score: 0.800000\n",
      "Iteration 6, loss = 0.47907594\n",
      "Validation score: 0.800000\n",
      "Iteration 7, loss = 0.45653656\n",
      "Validation score: 0.800000\n",
      "Iteration 8, loss = 0.44183015\n",
      "Validation score: 0.800000\n",
      "Iteration 9, loss = 0.43487906\n",
      "Validation score: 0.800000\n",
      "Iteration 10, loss = 0.42520000\n",
      "Validation score: 0.800000\n",
      "Iteration 11, loss = 0.41840145\n",
      "Validation score: 0.825000\n",
      "Iteration 12, loss = 0.40641492\n",
      "Validation score: 0.825000\n",
      "Iteration 13, loss = 0.39776023\n",
      "Validation score: 0.825000\n",
      "Iteration 14, loss = 0.38660147\n",
      "Validation score: 0.825000\n",
      "Iteration 15, loss = 0.37755622\n",
      "Validation score: 0.825000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70852852\n",
      "Validation score: 0.700000\n",
      "Iteration 2, loss = 0.61132130\n",
      "Validation score: 0.700000\n",
      "Iteration 3, loss = 0.58803234\n",
      "Validation score: 0.700000\n",
      "Iteration 4, loss = 0.54308127\n",
      "Validation score: 0.825000\n",
      "Iteration 5, loss = 0.49664871\n",
      "Validation score: 0.850000\n",
      "Iteration 6, loss = 0.46276283\n",
      "Validation score: 0.850000\n",
      "Iteration 7, loss = 0.44488050\n",
      "Validation score: 0.850000\n",
      "Iteration 8, loss = 0.43930700\n",
      "Validation score: 0.850000\n",
      "Iteration 9, loss = 0.41949331\n",
      "Validation score: 0.850000\n",
      "Iteration 10, loss = 0.41249400\n",
      "Validation score: 0.850000\n",
      "Iteration 11, loss = 0.40578725\n",
      "Validation score: 0.850000\n",
      "Iteration 12, loss = 0.39424937\n",
      "Validation score: 0.850000\n",
      "Iteration 13, loss = 0.38215820\n",
      "Validation score: 0.850000\n",
      "Iteration 14, loss = 0.37378522\n",
      "Validation score: 0.850000\n",
      "Iteration 15, loss = 0.36696655\n",
      "Validation score: 0.850000\n",
      "Iteration 16, loss = 0.35534418\n",
      "Validation score: 0.875000\n",
      "Iteration 17, loss = 0.34562618\n",
      "Validation score: 0.875000\n",
      "Iteration 18, loss = 0.33654933\n",
      "Validation score: 0.850000\n",
      "Iteration 19, loss = 0.32832903\n",
      "Validation score: 0.875000\n",
      "Iteration 20, loss = 0.32286194\n",
      "Validation score: 0.850000\n",
      "Iteration 21, loss = 0.31269482\n",
      "Validation score: 0.850000\n",
      "Iteration 22, loss = 0.30264748\n",
      "Validation score: 0.850000\n",
      "Iteration 23, loss = 0.29533452\n",
      "Validation score: 0.875000\n",
      "Iteration 24, loss = 0.28919898\n",
      "Validation score: 0.850000\n",
      "Iteration 25, loss = 0.28085647\n",
      "Validation score: 0.850000\n",
      "Iteration 26, loss = 0.27200123\n",
      "Validation score: 0.850000\n",
      "Iteration 27, loss = 0.27555175\n",
      "Validation score: 0.800000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71016741\n",
      "Validation score: 0.700000\n",
      "Iteration 2, loss = 0.60829307\n",
      "Validation score: 0.700000\n",
      "Iteration 3, loss = 0.58447878\n",
      "Validation score: 0.700000\n",
      "Iteration 4, loss = 0.53693744\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.48948258\n",
      "Validation score: 0.775000\n",
      "Iteration 6, loss = 0.45364609\n",
      "Validation score: 0.775000\n",
      "Iteration 7, loss = 0.43074534\n",
      "Validation score: 0.775000\n",
      "Iteration 8, loss = 0.42109869\n",
      "Validation score: 0.775000\n",
      "Iteration 9, loss = 0.40742569\n",
      "Validation score: 0.775000\n",
      "Iteration 10, loss = 0.40314407\n",
      "Validation score: 0.775000\n",
      "Iteration 11, loss = 0.39435148\n",
      "Validation score: 0.775000\n",
      "Iteration 12, loss = 0.38158556\n",
      "Validation score: 0.725000\n",
      "Iteration 13, loss = 0.37236930\n",
      "Validation score: 0.725000\n",
      "Iteration 14, loss = 0.36481911\n",
      "Validation score: 0.750000\n",
      "Iteration 15, loss = 0.35696306\n",
      "Validation score: 0.750000\n",
      "Iteration 16, loss = 0.34690235\n",
      "Validation score: 0.750000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.71098243\n",
      "Validation score: 0.700000\n",
      "Iteration 2, loss = 0.60905004\n",
      "Validation score: 0.700000\n",
      "Iteration 3, loss = 0.57808539\n",
      "Validation score: 0.700000\n",
      "Iteration 4, loss = 0.52153731\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.46839625\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.43148096\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.40943281\n",
      "Validation score: 0.750000\n",
      "Iteration 8, loss = 0.40276876\n",
      "Validation score: 0.750000\n",
      "Iteration 9, loss = 0.39122861\n",
      "Validation score: 0.750000\n",
      "Iteration 10, loss = 0.38309373\n",
      "Validation score: 0.750000\n",
      "Iteration 11, loss = 0.37553173\n",
      "Validation score: 0.750000\n",
      "Iteration 12, loss = 0.36210631\n",
      "Validation score: 0.750000\n",
      "Iteration 13, loss = 0.35421685\n",
      "Validation score: 0.725000\n",
      "Iteration 14, loss = 0.34795462\n",
      "Validation score: 0.725000\n",
      "Iteration 15, loss = 0.33866240\n",
      "Validation score: 0.725000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.70917257\n",
      "Validation score: 0.700000\n",
      "Iteration 2, loss = 0.60383257\n",
      "Validation score: 0.700000\n",
      "Iteration 3, loss = 0.58736421\n",
      "Validation score: 0.700000\n",
      "Iteration 4, loss = 0.53903122\n",
      "Validation score: 0.800000\n",
      "Iteration 5, loss = 0.48734804\n",
      "Validation score: 0.775000\n",
      "Iteration 6, loss = 0.45395788\n",
      "Validation score: 0.775000\n",
      "Iteration 7, loss = 0.43100415\n",
      "Validation score: 0.800000\n",
      "Iteration 8, loss = 0.41992645\n",
      "Validation score: 0.800000\n",
      "Iteration 9, loss = 0.41437943\n",
      "Validation score: 0.800000\n",
      "Iteration 10, loss = 0.40329801\n",
      "Validation score: 0.800000\n",
      "Iteration 11, loss = 0.39404282\n",
      "Validation score: 0.800000\n",
      "Iteration 12, loss = 0.38314595\n",
      "Validation score: 0.800000\n",
      "Iteration 13, loss = 0.37416445\n",
      "Validation score: 0.800000\n",
      "Iteration 14, loss = 0.36287338\n",
      "Validation score: 0.800000\n",
      "Iteration 15, loss = 0.35535846\n",
      "Validation score: 0.800000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69609853\n",
      "Validation score: 0.700000\n",
      "Iteration 2, loss = 0.61809766\n",
      "Validation score: 0.700000\n",
      "Iteration 3, loss = 0.55230942\n",
      "Validation score: 0.880000\n",
      "Iteration 4, loss = 0.50571522\n",
      "Validation score: 0.880000\n",
      "Iteration 5, loss = 0.46542416\n",
      "Validation score: 0.880000\n",
      "Iteration 6, loss = 0.43978385\n",
      "Validation score: 0.880000\n",
      "Iteration 7, loss = 0.43648977\n",
      "Validation score: 0.900000\n",
      "Iteration 8, loss = 0.42709365\n",
      "Validation score: 0.860000\n",
      "Iteration 9, loss = 0.41675989\n",
      "Validation score: 0.900000\n",
      "Iteration 10, loss = 0.41191010\n",
      "Validation score: 0.880000\n",
      "Iteration 11, loss = 0.40352496\n",
      "Validation score: 0.880000\n",
      "Iteration 12, loss = 0.39950107\n",
      "Validation score: 0.880000\n",
      "Iteration 13, loss = 0.38850131\n",
      "Validation score: 0.880000\n",
      "Iteration 14, loss = 0.38115226\n",
      "Validation score: 0.840000\n",
      "Iteration 15, loss = 0.37126055\n",
      "Validation score: 0.860000\n",
      "Iteration 16, loss = 0.36340556\n",
      "Validation score: 0.860000\n",
      "Iteration 17, loss = 0.35826404\n",
      "Validation score: 0.880000\n",
      "Iteration 18, loss = 0.35527036\n",
      "Validation score: 0.880000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "Best parameters found: {'learning_rate_init': 0.1}\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "da29b721-f0cc-495d-8399-fe2ab4f95a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.69609853\n",
      "Validation score: 0.700000\n",
      "Iteration 2, loss = 0.61809766\n",
      "Validation score: 0.700000\n",
      "Iteration 3, loss = 0.55230942\n",
      "Validation score: 0.880000\n",
      "Iteration 4, loss = 0.50571522\n",
      "Validation score: 0.880000\n",
      "Iteration 5, loss = 0.46542416\n",
      "Validation score: 0.880000\n",
      "Iteration 6, loss = 0.43978385\n",
      "Validation score: 0.880000\n",
      "Iteration 7, loss = 0.43648977\n",
      "Validation score: 0.900000\n",
      "Iteration 8, loss = 0.42709365\n",
      "Validation score: 0.860000\n",
      "Iteration 9, loss = 0.41675989\n",
      "Validation score: 0.900000\n",
      "Iteration 10, loss = 0.41191010\n",
      "Validation score: 0.880000\n",
      "Iteration 11, loss = 0.40352496\n",
      "Validation score: 0.880000\n",
      "Iteration 12, loss = 0.39950107\n",
      "Validation score: 0.880000\n",
      "Iteration 13, loss = 0.38850131\n",
      "Validation score: 0.880000\n",
      "Iteration 14, loss = 0.38115226\n",
      "Validation score: 0.840000\n",
      "Iteration 15, loss = 0.37126055\n",
      "Validation score: 0.860000\n",
      "Iteration 16, loss = 0.36340556\n",
      "Validation score: 0.860000\n",
      "Iteration 17, loss = 0.35826404\n",
      "Validation score: 0.880000\n",
      "Iteration 18, loss = 0.35527036\n",
      "Validation score: 0.880000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(100, 100, 100),\n",
       "              learning_rate_init=0.1, random_state=42, solver=&#x27;sgd&#x27;, tol=1e-09,\n",
       "              verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(100, 100, 100),\n",
       "              learning_rate_init=0.1, random_state=42, solver=&#x27;sgd&#x27;, tol=1e-09,\n",
       "              verbose=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(early_stopping=True, hidden_layer_sizes=(100, 100, 100),\n",
       "              learning_rate_init=0.1, random_state=42, solver='sgd', tol=1e-09,\n",
       "              verbose=10)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf = grid_search.best_estimator_\n",
    "best_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "24417c4b-d81a-4676-b27c-cf364b351f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.74749777\n",
      "Validation score: 0.280000\n",
      "Iteration 2, loss = 0.74169468\n",
      "Validation score: 0.300000\n",
      "Iteration 3, loss = 0.73316285\n",
      "Validation score: 0.300000\n",
      "Iteration 4, loss = 0.72331046\n",
      "Validation score: 0.420000\n",
      "Iteration 5, loss = 0.71292642\n",
      "Validation score: 0.480000\n",
      "Iteration 6, loss = 0.70245316\n",
      "Validation score: 0.540000\n",
      "Iteration 7, loss = 0.69224793\n",
      "Validation score: 0.640000\n",
      "Iteration 8, loss = 0.68304146\n",
      "Validation score: 0.620000\n",
      "Iteration 9, loss = 0.67416586\n",
      "Validation score: 0.620000\n",
      "Iteration 10, loss = 0.66640131\n",
      "Validation score: 0.640000\n",
      "Iteration 11, loss = 0.65920916\n",
      "Validation score: 0.680000\n",
      "Iteration 12, loss = 0.65238912\n",
      "Validation score: 0.700000\n",
      "Iteration 13, loss = 0.64637556\n",
      "Validation score: 0.720000\n",
      "Iteration 14, loss = 0.64102097\n",
      "Validation score: 0.700000\n",
      "Iteration 15, loss = 0.63594447\n",
      "Validation score: 0.700000\n",
      "Iteration 16, loss = 0.63175923\n",
      "Validation score: 0.700000\n",
      "Iteration 17, loss = 0.62779235\n",
      "Validation score: 0.700000\n",
      "Iteration 18, loss = 0.62448738\n",
      "Validation score: 0.700000\n",
      "Iteration 19, loss = 0.62168711\n",
      "Validation score: 0.700000\n",
      "Iteration 20, loss = 0.61882312\n",
      "Validation score: 0.700000\n",
      "Iteration 21, loss = 0.61641487\n",
      "Validation score: 0.700000\n",
      "Iteration 22, loss = 0.61409103\n",
      "Validation score: 0.700000\n",
      "Iteration 23, loss = 0.61196644\n",
      "Validation score: 0.700000\n",
      "Iteration 24, loss = 0.60991668\n",
      "Validation score: 0.700000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(100, 100, 100),\n",
       "              random_state=42, solver=&#x27;sgd&#x27;, tol=1e-09, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(100, 100, 100),\n",
       "              random_state=42, solver=&#x27;sgd&#x27;, tol=1e-09, verbose=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(early_stopping=True, hidden_layer_sizes=(100, 100, 100),\n",
       "              random_state=42, solver='sgd', tol=1e-09, verbose=10)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "61fbf9ff-8eed-456d-a5b1-f0e28b831f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7886178861788617"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = best_clf.score(X_test, Y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ccdea133-dcfa-4fef-8124-b77b5d57d751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[learning_curve] Training set sizes: [ 39  78 117 156 196 235 274 313 352 392]\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.70269570\n",
      "Validation score: 0.750000\n",
      "Iteration 2, loss = 0.66517887\n",
      "Validation score: 0.500000\n",
      "Iteration 3, loss = 0.62066764\n",
      "Validation score: 0.500000\n",
      "Iteration 4, loss = 0.57411681\n",
      "Validation score: 0.500000\n",
      "Iteration 5, loss = 0.52414876\n",
      "Validation score: 0.500000\n",
      "Iteration 6, loss = 0.47150988\n",
      "Validation score: 0.500000\n",
      "Iteration 7, loss = 0.41547065\n",
      "Validation score: 0.250000\n",
      "Iteration 8, loss = 0.35769670\n",
      "Validation score: 0.250000\n",
      "Iteration 9, loss = 0.30378935\n",
      "Validation score: 0.250000\n",
      "Iteration 10, loss = 0.25605833\n",
      "Validation score: 0.250000\n",
      "Iteration 11, loss = 0.21426071\n",
      "Validation score: 0.000000\n",
      "Iteration 12, loss = 0.17804559\n",
      "Validation score: 0.000000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.667, test=0.646) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69280783\n",
      "Validation score: 0.875000\n",
      "Iteration 2, loss = 0.66121682\n",
      "Validation score: 0.625000\n",
      "Iteration 3, loss = 0.63012615\n",
      "Validation score: 0.625000\n",
      "Iteration 4, loss = 0.60325768\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.57820672\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.55142254\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.52202325\n",
      "Validation score: 0.750000\n",
      "Iteration 8, loss = 0.49133460\n",
      "Validation score: 0.750000\n",
      "Iteration 9, loss = 0.46309557\n",
      "Validation score: 0.625000\n",
      "Iteration 10, loss = 0.43865314\n",
      "Validation score: 0.625000\n",
      "Iteration 11, loss = 0.41657072\n",
      "Validation score: 0.625000\n",
      "Iteration 12, loss = 0.39660259\n",
      "Validation score: 0.625000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.679, test=0.697) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69095663\n",
      "Validation score: 0.666667\n",
      "Iteration 2, loss = 0.65324155\n",
      "Validation score: 0.666667\n",
      "Iteration 3, loss = 0.61965319\n",
      "Validation score: 0.666667\n",
      "Iteration 4, loss = 0.59443688\n",
      "Validation score: 0.666667\n",
      "Iteration 5, loss = 0.57302567\n",
      "Validation score: 0.666667\n",
      "Iteration 6, loss = 0.54962882\n",
      "Validation score: 0.666667\n",
      "Iteration 7, loss = 0.52198107\n",
      "Validation score: 0.666667\n",
      "Iteration 8, loss = 0.49154558\n",
      "Validation score: 0.666667\n",
      "Iteration 9, loss = 0.46407083\n",
      "Validation score: 0.666667\n",
      "Iteration 10, loss = 0.44082343\n",
      "Validation score: 0.583333\n",
      "Iteration 11, loss = 0.42058484\n",
      "Validation score: 0.583333\n",
      "Iteration 12, loss = 0.40312412\n",
      "Validation score: 0.583333\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.684, test=0.707) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.70068775\n",
      "Validation score: 0.625000\n",
      "Iteration 2, loss = 0.66073586\n",
      "Validation score: 0.687500\n",
      "Iteration 3, loss = 0.62289407\n",
      "Validation score: 0.687500\n",
      "Iteration 4, loss = 0.59198680\n",
      "Validation score: 0.687500\n",
      "Iteration 5, loss = 0.56562333\n",
      "Validation score: 0.687500\n",
      "Iteration 6, loss = 0.53870203\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.50827507\n",
      "Validation score: 0.812500\n",
      "Iteration 8, loss = 0.47576140\n",
      "Validation score: 0.687500\n",
      "Iteration 9, loss = 0.44661897\n",
      "Validation score: 0.687500\n",
      "Iteration 10, loss = 0.42354915\n",
      "Validation score: 0.687500\n",
      "Iteration 11, loss = 0.40564098\n",
      "Validation score: 0.625000\n",
      "Iteration 12, loss = 0.39149159\n",
      "Validation score: 0.625000\n",
      "Iteration 13, loss = 0.38030465\n",
      "Validation score: 0.625000\n",
      "Iteration 14, loss = 0.37148010\n",
      "Validation score: 0.625000\n",
      "Iteration 15, loss = 0.36363198\n",
      "Validation score: 0.625000\n",
      "Iteration 16, loss = 0.35568044\n",
      "Validation score: 0.625000\n",
      "Iteration 17, loss = 0.34716876\n",
      "Validation score: 0.625000\n",
      "Iteration 18, loss = 0.33741725\n",
      "Validation score: 0.625000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.814, test=0.808) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69499086\n",
      "Validation score: 0.700000\n",
      "Iteration 2, loss = 0.65865138\n",
      "Validation score: 0.700000\n",
      "Iteration 3, loss = 0.62472222\n",
      "Validation score: 0.700000\n",
      "Iteration 4, loss = 0.59665866\n",
      "Validation score: 0.700000\n",
      "Iteration 5, loss = 0.57134995\n",
      "Validation score: 0.700000\n",
      "Iteration 6, loss = 0.54486975\n",
      "Validation score: 0.700000\n",
      "Iteration 7, loss = 0.51545613\n",
      "Validation score: 0.750000\n",
      "Iteration 8, loss = 0.48533968\n",
      "Validation score: 0.800000\n",
      "Iteration 9, loss = 0.45935917\n",
      "Validation score: 0.800000\n",
      "Iteration 10, loss = 0.43991926\n",
      "Validation score: 0.800000\n",
      "Iteration 11, loss = 0.42654618\n",
      "Validation score: 0.800000\n",
      "Iteration 12, loss = 0.41716715\n",
      "Validation score: 0.800000\n",
      "Iteration 13, loss = 0.41046357\n",
      "Validation score: 0.800000\n",
      "Iteration 14, loss = 0.40502574\n",
      "Validation score: 0.800000\n",
      "Iteration 15, loss = 0.39943498\n",
      "Validation score: 0.750000\n",
      "Iteration 16, loss = 0.39270853\n",
      "Validation score: 0.750000\n",
      "Iteration 17, loss = 0.38504961\n",
      "Validation score: 0.750000\n",
      "Iteration 18, loss = 0.37619119\n",
      "Validation score: 0.750000\n",
      "Iteration 19, loss = 0.36661268\n",
      "Validation score: 0.750000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.811, test=0.818) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69040609\n",
      "Validation score: 0.708333\n",
      "Iteration 2, loss = 0.62808781\n",
      "Validation score: 0.708333\n",
      "Iteration 3, loss = 0.58375439\n",
      "Validation score: 0.708333\n",
      "Iteration 4, loss = 0.55115899\n",
      "Validation score: 0.791667\n",
      "Iteration 5, loss = 0.50704469\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.49037554\n",
      "Validation score: 0.666667\n",
      "Iteration 7, loss = 0.47284641\n",
      "Validation score: 0.750000\n",
      "Iteration 8, loss = 0.45755642\n",
      "Validation score: 0.750000\n",
      "Iteration 9, loss = 0.44531018\n",
      "Validation score: 0.708333\n",
      "Iteration 10, loss = 0.48586539\n",
      "Validation score: 0.750000\n",
      "Iteration 11, loss = 0.41822374\n",
      "Validation score: 0.833333\n",
      "Iteration 12, loss = 0.43031126\n",
      "Validation score: 0.833333\n",
      "Iteration 13, loss = 0.43520631\n",
      "Validation score: 0.791667\n",
      "Iteration 14, loss = 0.41711135\n",
      "Validation score: 0.791667\n",
      "Iteration 15, loss = 0.42109589\n",
      "Validation score: 0.791667\n",
      "Iteration 16, loss = 0.40969032\n",
      "Validation score: 0.791667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, loss = 0.40751935\n",
      "Validation score: 0.833333\n",
      "Iteration 18, loss = 0.39762345\n",
      "Validation score: 0.791667\n",
      "Iteration 19, loss = 0.38845628\n",
      "Validation score: 0.791667\n",
      "Iteration 20, loss = 0.36854149\n",
      "Validation score: 0.791667\n",
      "Iteration 21, loss = 0.35942262\n",
      "Validation score: 0.750000\n",
      "Iteration 22, loss = 0.35027367\n",
      "Validation score: 0.750000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.821, test=0.838) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68870844\n",
      "Validation score: 0.678571\n",
      "Iteration 2, loss = 0.61408406\n",
      "Validation score: 0.678571\n",
      "Iteration 3, loss = 0.57713448\n",
      "Validation score: 0.678571\n",
      "Iteration 4, loss = 0.53867223\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.48373927\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.46353535\n",
      "Validation score: 0.785714\n",
      "Iteration 7, loss = 0.45327857\n",
      "Validation score: 0.785714\n",
      "Iteration 8, loss = 0.45825370\n",
      "Validation score: 0.785714\n",
      "Iteration 9, loss = 0.42619176\n",
      "Validation score: 0.714286\n",
      "Iteration 10, loss = 0.42871301\n",
      "Validation score: 0.714286\n",
      "Iteration 11, loss = 0.40480031\n",
      "Validation score: 0.750000\n",
      "Iteration 12, loss = 0.38999333\n",
      "Validation score: 0.750000\n",
      "Iteration 13, loss = 0.37791301\n",
      "Validation score: 0.750000\n",
      "Iteration 14, loss = 0.37151031\n",
      "Validation score: 0.785714\n",
      "Iteration 15, loss = 0.36795443\n",
      "Validation score: 0.750000\n",
      "Iteration 16, loss = 0.35211677\n",
      "Validation score: 0.714286\n",
      "Iteration 17, loss = 0.34170489\n",
      "Validation score: 0.678571\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.807, test=0.859) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69407595\n",
      "Validation score: 0.687500\n",
      "Iteration 2, loss = 0.62367068\n",
      "Validation score: 0.687500\n",
      "Iteration 3, loss = 0.57510569\n",
      "Validation score: 0.687500\n",
      "Iteration 4, loss = 0.53700928\n",
      "Validation score: 0.781250\n",
      "Iteration 5, loss = 0.48924683\n",
      "Validation score: 0.812500\n",
      "Iteration 6, loss = 0.44860270\n",
      "Validation score: 0.781250\n",
      "Iteration 7, loss = 0.43715569\n",
      "Validation score: 0.812500\n",
      "Iteration 8, loss = 0.42695300\n",
      "Validation score: 0.812500\n",
      "Iteration 9, loss = 0.42124241\n",
      "Validation score: 0.781250\n",
      "Iteration 10, loss = 0.41038672\n",
      "Validation score: 0.687500\n",
      "Iteration 11, loss = 0.39921390\n",
      "Validation score: 0.781250\n",
      "Iteration 12, loss = 0.38660488\n",
      "Validation score: 0.812500\n",
      "Iteration 13, loss = 0.37852826\n",
      "Validation score: 0.781250\n",
      "Iteration 14, loss = 0.36427017\n",
      "Validation score: 0.718750\n",
      "Iteration 15, loss = 0.34940162\n",
      "Validation score: 0.718750\n",
      "Iteration 16, loss = 0.34425053\n",
      "Validation score: 0.687500\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.808, test=0.859) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68684455\n",
      "Validation score: 0.666667\n",
      "Iteration 2, loss = 0.62331360\n",
      "Validation score: 0.666667\n",
      "Iteration 3, loss = 0.58513215\n",
      "Validation score: 0.694444\n",
      "Iteration 4, loss = 0.53749723\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.49013049\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.46012067\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.44592313\n",
      "Validation score: 0.750000\n",
      "Iteration 8, loss = 0.43806854\n",
      "Validation score: 0.750000\n",
      "Iteration 9, loss = 0.43814852\n",
      "Validation score: 0.750000\n",
      "Iteration 10, loss = 0.42562918\n",
      "Validation score: 0.750000\n",
      "Iteration 11, loss = 0.41184555\n",
      "Validation score: 0.694444\n",
      "Iteration 12, loss = 0.39944722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.694444\n",
      "Iteration 13, loss = 0.38888098\n",
      "Validation score: 0.694444\n",
      "Iteration 14, loss = 0.37813188\n",
      "Validation score: 0.722222\n",
      "Iteration 15, loss = 0.36773180\n",
      "Validation score: 0.722222\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.793, test=0.818) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68260778\n",
      "Validation score: 0.700000\n",
      "Iteration 2, loss = 0.61621451\n",
      "Validation score: 0.700000\n",
      "Iteration 3, loss = 0.57572408\n",
      "Validation score: 0.700000\n",
      "Iteration 4, loss = 0.53349158\n",
      "Validation score: 0.775000\n",
      "Iteration 5, loss = 0.48685041\n",
      "Validation score: 0.775000\n",
      "Iteration 6, loss = 0.46339627\n",
      "Validation score: 0.775000\n",
      "Iteration 7, loss = 0.45204695\n",
      "Validation score: 0.750000\n",
      "Iteration 8, loss = 0.44029590\n",
      "Validation score: 0.750000\n",
      "Iteration 9, loss = 0.43259284\n",
      "Validation score: 0.775000\n",
      "Iteration 10, loss = 0.43129122\n",
      "Validation score: 0.775000\n",
      "Iteration 11, loss = 0.41461115\n",
      "Validation score: 0.775000\n",
      "Iteration 12, loss = 0.40461638\n",
      "Validation score: 0.775000\n",
      "Iteration 13, loss = 0.39518049\n",
      "Validation score: 0.800000\n",
      "Iteration 14, loss = 0.38798929\n",
      "Validation score: 0.800000\n",
      "Iteration 15, loss = 0.38020769\n",
      "Validation score: 0.800000\n",
      "Iteration 16, loss = 0.36912869\n",
      "Validation score: 0.800000\n",
      "Iteration 17, loss = 0.36162676\n",
      "Validation score: 0.800000\n",
      "Iteration 18, loss = 0.35235970\n",
      "Validation score: 0.800000\n",
      "Iteration 19, loss = 0.34577372\n",
      "Validation score: 0.800000\n",
      "Iteration 20, loss = 0.33381264\n",
      "Validation score: 0.800000\n",
      "Iteration 21, loss = 0.32484405\n",
      "Validation score: 0.775000\n",
      "Iteration 22, loss = 0.31717011\n",
      "Validation score: 0.800000\n",
      "Iteration 23, loss = 0.31122911\n",
      "Validation score: 0.725000\n",
      "Iteration 24, loss = 0.30387147\n",
      "Validation score: 0.800000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.816, test=0.869) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68993306\n",
      "Validation score: 0.750000\n",
      "Iteration 2, loss = 0.65575795\n",
      "Validation score: 0.750000\n",
      "Iteration 3, loss = 0.61683135\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.57610738\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.53535932\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.49512037\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.45410018\n",
      "Validation score: 0.750000\n",
      "Iteration 8, loss = 0.41208851\n",
      "Validation score: 0.750000\n",
      "Iteration 9, loss = 0.36870907\n",
      "Validation score: 0.750000\n",
      "Iteration 10, loss = 0.32332562\n",
      "Validation score: 0.500000\n",
      "Iteration 11, loss = 0.27719161\n",
      "Validation score: 0.500000\n",
      "Iteration 12, loss = 0.23062006\n",
      "Validation score: 0.500000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.718, test=0.694) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.70164583\n",
      "Validation score: 0.875000\n",
      "Iteration 2, loss = 0.66845529\n",
      "Validation score: 0.750000\n",
      "Iteration 3, loss = 0.62812605\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.58389278\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.53809783\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.49199873\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.44642304\n",
      "Validation score: 0.875000\n",
      "Iteration 8, loss = 0.40362194\n",
      "Validation score: 0.875000\n",
      "Iteration 9, loss = 0.36717964\n",
      "Validation score: 0.875000\n",
      "Iteration 10, loss = 0.33770663\n",
      "Validation score: 0.875000\n",
      "Iteration 11, loss = 0.31441576\n",
      "Validation score: 0.875000\n",
      "Iteration 12, loss = 0.29410979\n",
      "Validation score: 0.875000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.679, test=0.704) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68754607\n",
      "Validation score: 0.666667\n",
      "Iteration 2, loss = 0.64698641\n",
      "Validation score: 0.666667\n",
      "Iteration 3, loss = 0.60835119\n",
      "Validation score: 0.666667\n",
      "Iteration 4, loss = 0.57507197\n",
      "Validation score: 0.666667\n",
      "Iteration 5, loss = 0.54406102\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.51027898\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.47413557\n",
      "Validation score: 0.750000\n",
      "Iteration 8, loss = 0.43933787\n",
      "Validation score: 0.833333\n",
      "Iteration 9, loss = 0.40707006\n",
      "Validation score: 0.833333\n",
      "Iteration 10, loss = 0.37845782\n",
      "Validation score: 0.833333\n",
      "Iteration 11, loss = 0.35500622\n",
      "Validation score: 0.916667\n",
      "Iteration 12, loss = 0.33647721\n",
      "Validation score: 0.916667\n",
      "Iteration 13, loss = 0.32111355\n",
      "Validation score: 0.916667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 tasks      | elapsed:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, loss = 0.30782344\n",
      "Validation score: 0.916667\n",
      "Iteration 15, loss = 0.29532766\n",
      "Validation score: 0.916667\n",
      "Iteration 16, loss = 0.28257854\n",
      "Validation score: 0.916667\n",
      "Iteration 17, loss = 0.27010256\n",
      "Validation score: 0.916667\n",
      "Iteration 18, loss = 0.25781968\n",
      "Validation score: 0.833333\n",
      "Iteration 19, loss = 0.24553648\n",
      "Validation score: 0.833333\n",
      "Iteration 20, loss = 0.23288818\n",
      "Validation score: 0.833333\n",
      "Iteration 21, loss = 0.21985291\n",
      "Validation score: 0.833333\n",
      "Iteration 22, loss = 0.20695593\n",
      "Validation score: 0.833333\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.880, test=0.806) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69886318\n",
      "Validation score: 0.750000\n",
      "Iteration 2, loss = 0.65520753\n",
      "Validation score: 0.687500\n",
      "Iteration 3, loss = 0.61376641\n",
      "Validation score: 0.687500\n",
      "Iteration 4, loss = 0.57881846\n",
      "Validation score: 0.687500\n",
      "Iteration 5, loss = 0.54784103\n",
      "Validation score: 0.687500\n",
      "Iteration 6, loss = 0.51527546\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.48011549\n",
      "Validation score: 0.750000\n",
      "Iteration 8, loss = 0.44540674\n",
      "Validation score: 0.875000\n",
      "Iteration 9, loss = 0.41446356\n",
      "Validation score: 0.875000\n",
      "Iteration 10, loss = 0.38912480\n",
      "Validation score: 0.875000\n",
      "Iteration 11, loss = 0.36969582\n",
      "Validation score: 0.812500\n",
      "Iteration 12, loss = 0.35498940\n",
      "Validation score: 0.875000\n",
      "Iteration 13, loss = 0.34293712\n",
      "Validation score: 0.875000\n",
      "Iteration 14, loss = 0.33180890\n",
      "Validation score: 0.812500\n",
      "Iteration 15, loss = 0.32029712\n",
      "Validation score: 0.750000\n",
      "Iteration 16, loss = 0.30824619\n",
      "Validation score: 0.750000\n",
      "Iteration 17, loss = 0.29615666\n",
      "Validation score: 0.750000\n",
      "Iteration 18, loss = 0.28439739\n",
      "Validation score: 0.750000\n",
      "Iteration 19, loss = 0.27271789\n",
      "Validation score: 0.750000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.859, test=0.796) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69716253\n",
      "Validation score: 0.700000\n",
      "Iteration 2, loss = 0.65936744\n",
      "Validation score: 0.700000\n",
      "Iteration 3, loss = 0.62363788\n",
      "Validation score: 0.700000\n",
      "Iteration 4, loss = 0.59313832\n",
      "Validation score: 0.700000\n",
      "Iteration 5, loss = 0.56525887\n",
      "Validation score: 0.700000\n",
      "Iteration 6, loss = 0.53565363\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.50347339\n",
      "Validation score: 0.800000\n",
      "Iteration 8, loss = 0.47162235\n",
      "Validation score: 0.850000\n",
      "Iteration 9, loss = 0.44429261\n",
      "Validation score: 0.800000\n",
      "Iteration 10, loss = 0.42319530\n",
      "Validation score: 0.800000\n",
      "Iteration 11, loss = 0.40796572\n",
      "Validation score: 0.800000\n",
      "Iteration 12, loss = 0.39764811\n",
      "Validation score: 0.800000\n",
      "Iteration 13, loss = 0.39058733\n",
      "Validation score: 0.800000\n",
      "Iteration 14, loss = 0.38492328\n",
      "Validation score: 0.800000\n",
      "Iteration 15, loss = 0.37928617\n",
      "Validation score: 0.800000\n",
      "Iteration 16, loss = 0.37291041\n",
      "Validation score: 0.800000\n",
      "Iteration 17, loss = 0.36580124\n",
      "Validation score: 0.800000\n",
      "Iteration 18, loss = 0.35804917\n",
      "Validation score: 0.800000\n",
      "Iteration 19, loss = 0.34976011\n",
      "Validation score: 0.800000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.842, test=0.806) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69208405\n",
      "Validation score: 0.708333\n",
      "Iteration 2, loss = 0.64591481\n",
      "Validation score: 0.708333\n",
      "Iteration 3, loss = 0.59388881\n",
      "Validation score: 0.708333\n",
      "Iteration 4, loss = 0.55971479\n",
      "Validation score: 0.791667\n",
      "Iteration 5, loss = 0.50963660\n",
      "Validation score: 0.708333\n",
      "Iteration 6, loss = 0.47985804\n",
      "Validation score: 0.708333\n",
      "Iteration 7, loss = 0.44030646\n",
      "Validation score: 0.708333\n",
      "Iteration 8, loss = 0.41997562\n",
      "Validation score: 0.708333\n",
      "Iteration 9, loss = 0.40707010\n",
      "Validation score: 0.541667\n",
      "Iteration 10, loss = 0.44383907\n",
      "Validation score: 0.791667\n",
      "Iteration 11, loss = 0.38088590\n",
      "Validation score: 0.791667\n",
      "Iteration 12, loss = 0.40020762\n",
      "Validation score: 0.791667\n",
      "Iteration 13, loss = 0.40204493\n",
      "Validation score: 0.791667\n",
      "Iteration 14, loss = 0.39274269\n",
      "Validation score: 0.791667\n",
      "Iteration 15, loss = 0.38336609\n",
      "Validation score: 0.791667\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.800, test=0.796) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68857245\n",
      "Validation score: 0.678571\n",
      "Iteration 2, loss = 0.61417709\n",
      "Validation score: 0.678571\n",
      "Iteration 3, loss = 0.57426313\n",
      "Validation score: 0.678571\n",
      "Iteration 4, loss = 0.52764645\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.46252188\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.42836863\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.41236714\n",
      "Validation score: 0.750000\n",
      "Iteration 8, loss = 0.40470434\n",
      "Validation score: 0.750000\n",
      "Iteration 9, loss = 0.39603695\n",
      "Validation score: 0.750000\n",
      "Iteration 10, loss = 0.39251318\n",
      "Validation score: 0.750000\n",
      "Iteration 11, loss = 0.35967567\n",
      "Validation score: 0.750000\n",
      "Iteration 12, loss = 0.34850264\n",
      "Validation score: 0.750000\n",
      "Iteration 13, loss = 0.33692572\n",
      "Validation score: 0.714286\n",
      "Iteration 14, loss = 0.33844709\n",
      "Validation score: 0.750000\n",
      "Iteration 15, loss = 0.32668622\n",
      "Validation score: 0.750000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.810, test=0.806) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69177158\n",
      "Validation score: 0.687500\n",
      "Iteration 2, loss = 0.62073888\n",
      "Validation score: 0.687500\n",
      "Iteration 3, loss = 0.56577367\n",
      "Validation score: 0.718750\n",
      "Iteration 4, loss = 0.51687492\n",
      "Validation score: 0.781250\n",
      "Iteration 5, loss = 0.46879932\n",
      "Validation score: 0.812500\n",
      "Iteration 6, loss = 0.42674457\n",
      "Validation score: 0.812500\n",
      "Iteration 7, loss = 0.41458339\n",
      "Validation score: 0.812500\n",
      "Iteration 8, loss = 0.40385496\n",
      "Validation score: 0.812500\n",
      "Iteration 9, loss = 0.39500891\n",
      "Validation score: 0.812500\n",
      "Iteration 10, loss = 0.37844798\n",
      "Validation score: 0.781250\n",
      "Iteration 11, loss = 0.36775229\n",
      "Validation score: 0.781250\n",
      "Iteration 12, loss = 0.36036417\n",
      "Validation score: 0.812500\n",
      "Iteration 13, loss = 0.35030763\n",
      "Validation score: 0.781250\n",
      "Iteration 14, loss = 0.33596893\n",
      "Validation score: 0.812500\n",
      "Iteration 15, loss = 0.32316500\n",
      "Validation score: 0.781250\n",
      "Iteration 16, loss = 0.31396180\n",
      "Validation score: 0.750000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.831, test=0.806) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68644846\n",
      "Validation score: 0.694444\n",
      "Iteration 2, loss = 0.62070314\n",
      "Validation score: 0.694444\n",
      "Iteration 3, loss = 0.57432454\n",
      "Validation score: 0.722222\n",
      "Iteration 4, loss = 0.51405729\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.46089246\n",
      "Validation score: 0.722222\n",
      "Iteration 6, loss = 0.42714751\n",
      "Validation score: 0.694444\n",
      "Iteration 7, loss = 0.41333593\n",
      "Validation score: 0.694444\n",
      "Iteration 8, loss = 0.40973779\n",
      "Validation score: 0.694444\n",
      "Iteration 9, loss = 0.41463194\n",
      "Validation score: 0.694444\n",
      "Iteration 10, loss = 0.39598040\n",
      "Validation score: 0.722222\n",
      "Iteration 11, loss = 0.37665255\n",
      "Validation score: 0.694444\n",
      "Iteration 12, loss = 0.36500257\n",
      "Validation score: 0.694444\n",
      "Iteration 13, loss = 0.35462926\n",
      "Validation score: 0.722222\n",
      "Iteration 14, loss = 0.35106979\n",
      "Validation score: 0.722222\n",
      "Iteration 15, loss = 0.33849910\n",
      "Validation score: 0.722222\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.818, test=0.806) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68365119\n",
      "Validation score: 0.700000\n",
      "Iteration 2, loss = 0.61462568\n",
      "Validation score: 0.700000\n",
      "Iteration 3, loss = 0.56604875\n",
      "Validation score: 0.700000\n",
      "Iteration 4, loss = 0.51614862\n",
      "Validation score: 0.775000\n",
      "Iteration 5, loss = 0.46077794\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.43194805\n",
      "Validation score: 0.725000\n",
      "Iteration 7, loss = 0.42427766\n",
      "Validation score: 0.725000\n",
      "Iteration 8, loss = 0.41117270\n",
      "Validation score: 0.725000\n",
      "Iteration 9, loss = 0.40040580\n",
      "Validation score: 0.725000\n",
      "Iteration 10, loss = 0.39291514\n",
      "Validation score: 0.725000\n",
      "Iteration 11, loss = 0.38147333\n",
      "Validation score: 0.725000\n",
      "Iteration 12, loss = 0.36834563\n",
      "Validation score: 0.725000\n",
      "Iteration 13, loss = 0.36035292\n",
      "Validation score: 0.750000\n",
      "Iteration 14, loss = 0.35535998\n",
      "Validation score: 0.700000\n",
      "Iteration 15, loss = 0.34573302\n",
      "Validation score: 0.750000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.816, test=0.806) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68993306\n",
      "Validation score: 0.750000\n",
      "Iteration 2, loss = 0.65575795\n",
      "Validation score: 0.750000\n",
      "Iteration 3, loss = 0.61683135\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.57610738\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.53535932\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.49512037\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.45410018\n",
      "Validation score: 0.750000\n",
      "Iteration 8, loss = 0.41208851\n",
      "Validation score: 0.750000\n",
      "Iteration 9, loss = 0.36870907\n",
      "Validation score: 0.750000\n",
      "Iteration 10, loss = 0.32332562\n",
      "Validation score: 0.500000\n",
      "Iteration 11, loss = 0.27719161\n",
      "Validation score: 0.500000\n",
      "Iteration 12, loss = 0.23062006\n",
      "Validation score: 0.500000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.718, test=0.571) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.70164583\n",
      "Validation score: 0.875000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.66845529\n",
      "Validation score: 0.750000\n",
      "Iteration 3, loss = 0.62812605\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.58389278\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.53809783\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.49199873\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.44642304\n",
      "Validation score: 0.875000\n",
      "Iteration 8, loss = 0.40362194\n",
      "Validation score: 0.875000\n",
      "Iteration 9, loss = 0.36717964\n",
      "Validation score: 0.875000\n",
      "Iteration 10, loss = 0.33770663\n",
      "Validation score: 0.875000\n",
      "Iteration 11, loss = 0.31441576\n",
      "Validation score: 0.875000\n",
      "Iteration 12, loss = 0.29410979\n",
      "Validation score: 0.875000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.679, test=0.592) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69453203\n",
      "Validation score: 0.750000\n",
      "Iteration 2, loss = 0.66288659\n",
      "Validation score: 0.750000\n",
      "Iteration 3, loss = 0.62834763\n",
      "Validation score: 0.666667\n",
      "Iteration 4, loss = 0.59446649\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.56127393\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.52791677\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.49429030\n",
      "Validation score: 0.916667\n",
      "Iteration 8, loss = 0.46115731\n",
      "Validation score: 0.916667\n",
      "Iteration 9, loss = 0.43031997\n",
      "Validation score: 0.916667\n",
      "Iteration 10, loss = 0.40358064\n",
      "Validation score: 0.916667\n",
      "Iteration 11, loss = 0.38162671\n",
      "Validation score: 0.833333\n",
      "Iteration 12, loss = 0.36378157\n",
      "Validation score: 0.833333\n",
      "Iteration 13, loss = 0.34906480\n",
      "Validation score: 0.833333\n",
      "Iteration 14, loss = 0.33607034\n",
      "Validation score: 0.833333\n",
      "Iteration 15, loss = 0.32368474\n",
      "Validation score: 0.833333\n",
      "Iteration 16, loss = 0.31134292\n",
      "Validation score: 0.833333\n",
      "Iteration 17, loss = 0.29941750\n",
      "Validation score: 0.916667\n",
      "Iteration 18, loss = 0.28745440\n",
      "Validation score: 0.916667\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.846, test=0.755) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69072277\n",
      "Validation score: 0.812500\n",
      "Iteration 2, loss = 0.65807601\n",
      "Validation score: 0.687500\n",
      "Iteration 3, loss = 0.62559969\n",
      "Validation score: 0.687500\n",
      "Iteration 4, loss = 0.59632319\n",
      "Validation score: 0.812500\n",
      "Iteration 5, loss = 0.56829446\n",
      "Validation score: 0.812500\n",
      "Iteration 6, loss = 0.53848828\n",
      "Validation score: 0.812500\n",
      "Iteration 7, loss = 0.50713672\n",
      "Validation score: 0.875000\n",
      "Iteration 8, loss = 0.47626191\n",
      "Validation score: 0.875000\n",
      "Iteration 9, loss = 0.44816414\n",
      "Validation score: 0.875000\n",
      "Iteration 10, loss = 0.42404816\n",
      "Validation score: 0.875000\n",
      "Iteration 11, loss = 0.40411395\n",
      "Validation score: 0.937500\n",
      "Iteration 12, loss = 0.38773601\n",
      "Validation score: 0.937500\n",
      "Iteration 13, loss = 0.37405535\n",
      "Validation score: 0.937500\n",
      "Iteration 14, loss = 0.36218556\n",
      "Validation score: 0.937500\n",
      "Iteration 15, loss = 0.35133753\n",
      "Validation score: 0.937500\n",
      "Iteration 16, loss = 0.34098640\n",
      "Validation score: 0.937500\n",
      "Iteration 17, loss = 0.33066682\n",
      "Validation score: 0.937500\n",
      "Iteration 18, loss = 0.32024362\n",
      "Validation score: 0.937500\n",
      "Iteration 19, loss = 0.30946485\n",
      "Validation score: 0.937500\n",
      "Iteration 20, loss = 0.29853109\n",
      "Validation score: 0.937500\n",
      "Iteration 21, loss = 0.28727151\n",
      "Validation score: 0.937500\n",
      "Iteration 22, loss = 0.27609102\n",
      "Validation score: 0.875000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.865, test=0.735) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69043530\n",
      "Validation score: 0.750000\n",
      "Iteration 2, loss = 0.65305361\n",
      "Validation score: 0.700000\n",
      "Iteration 3, loss = 0.61857538\n",
      "Validation score: 0.700000\n",
      "Iteration 4, loss = 0.59102362\n",
      "Validation score: 0.700000\n",
      "Iteration 5, loss = 0.56717647\n",
      "Validation score: 0.800000\n",
      "Iteration 6, loss = 0.54182070\n",
      "Validation score: 0.850000\n",
      "Iteration 7, loss = 0.51304455\n",
      "Validation score: 0.900000\n",
      "Iteration 8, loss = 0.48346849\n",
      "Validation score: 0.900000\n",
      "Iteration 9, loss = 0.45644633\n",
      "Validation score: 0.900000\n",
      "Iteration 10, loss = 0.43358531\n",
      "Validation score: 0.900000\n",
      "Iteration 11, loss = 0.41543233\n",
      "Validation score: 0.900000\n",
      "Iteration 12, loss = 0.40130180\n",
      "Validation score: 0.950000\n",
      "Iteration 13, loss = 0.39030851\n",
      "Validation score: 0.950000\n",
      "Iteration 14, loss = 0.38161137\n",
      "Validation score: 0.950000\n",
      "Iteration 15, loss = 0.37403803\n",
      "Validation score: 0.900000\n",
      "Iteration 16, loss = 0.36650588\n",
      "Validation score: 0.850000\n",
      "Iteration 17, loss = 0.35867041\n",
      "Validation score: 0.850000\n",
      "Iteration 18, loss = 0.35029080\n",
      "Validation score: 0.900000\n",
      "Iteration 19, loss = 0.34163612\n",
      "Validation score: 0.850000\n",
      "Iteration 20, loss = 0.33272962\n",
      "Validation score: 0.850000\n",
      "Iteration 21, loss = 0.32354594\n",
      "Validation score: 0.850000\n",
      "Iteration 22, loss = 0.31435101\n",
      "Validation score: 0.850000\n",
      "Iteration 23, loss = 0.30506338\n",
      "Validation score: 0.850000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.847, test=0.786) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68639342\n",
      "Validation score: 0.708333\n",
      "Iteration 2, loss = 0.62774612\n",
      "Validation score: 0.708333\n",
      "Iteration 3, loss = 0.58572324\n",
      "Validation score: 0.708333\n",
      "Iteration 4, loss = 0.55594471\n",
      "Validation score: 0.875000\n",
      "Iteration 5, loss = 0.50364904\n",
      "Validation score: 0.875000\n",
      "Iteration 6, loss = 0.47838257\n",
      "Validation score: 0.875000\n",
      "Iteration 7, loss = 0.44768354\n",
      "Validation score: 0.833333\n",
      "Iteration 8, loss = 0.43315015\n",
      "Validation score: 0.875000\n",
      "Iteration 9, loss = 0.42499629\n",
      "Validation score: 0.833333\n",
      "Iteration 10, loss = 0.49380364\n",
      "Validation score: 0.916667\n",
      "Iteration 11, loss = 0.42159744\n",
      "Validation score: 0.916667\n",
      "Iteration 12, loss = 0.43676197\n",
      "Validation score: 0.916667\n",
      "Iteration 13, loss = 0.42190368\n",
      "Validation score: 0.875000\n",
      "Iteration 14, loss = 0.46075797\n",
      "Validation score: 0.833333\n",
      "Iteration 15, loss = 0.49901226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 tasks      | elapsed:    1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.875000\n",
      "Iteration 16, loss = 0.45756163\n",
      "Validation score: 0.875000\n",
      "Iteration 17, loss = 0.40585717\n",
      "Validation score: 0.833333\n",
      "Iteration 18, loss = 0.42172109\n",
      "Validation score: 0.833333\n",
      "Iteration 19, loss = 0.40922308\n",
      "Validation score: 0.833333\n",
      "Iteration 20, loss = 0.39151435\n",
      "Validation score: 0.916667\n",
      "Iteration 21, loss = 0.37895696\n",
      "Validation score: 0.916667\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.826, test=0.755) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68277200\n",
      "Validation score: 0.678571\n",
      "Iteration 2, loss = 0.60726682\n",
      "Validation score: 0.678571\n",
      "Iteration 3, loss = 0.57433670\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.52915812\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.46991097\n",
      "Validation score: 0.785714\n",
      "Iteration 6, loss = 0.43806091\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.42312271\n",
      "Validation score: 0.750000\n",
      "Iteration 8, loss = 0.42031495\n",
      "Validation score: 0.785714\n",
      "Iteration 9, loss = 0.40318427\n",
      "Validation score: 0.750000\n",
      "Iteration 10, loss = 0.40803996\n",
      "Validation score: 0.785714\n",
      "Iteration 11, loss = 0.37755711\n",
      "Validation score: 0.785714\n",
      "Iteration 12, loss = 0.36537985\n",
      "Validation score: 0.750000\n",
      "Iteration 13, loss = 0.36239796\n",
      "Validation score: 0.714286\n",
      "Iteration 14, loss = 0.37087524\n",
      "Validation score: 0.714286\n",
      "Iteration 15, loss = 0.35922113\n",
      "Validation score: 0.750000\n",
      "Iteration 16, loss = 0.33257046\n",
      "Validation score: 0.714286\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.818, test=0.806) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68682927\n",
      "Validation score: 0.687500\n",
      "Iteration 2, loss = 0.61708810\n",
      "Validation score: 0.687500\n",
      "Iteration 3, loss = 0.56842377\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.52490811\n",
      "Validation score: 0.812500\n",
      "Iteration 5, loss = 0.48047546\n",
      "Validation score: 0.875000\n",
      "Iteration 6, loss = 0.43445544\n",
      "Validation score: 0.875000\n",
      "Iteration 7, loss = 0.41878510\n",
      "Validation score: 0.875000\n",
      "Iteration 8, loss = 0.40728930\n",
      "Validation score: 0.875000\n",
      "Iteration 9, loss = 0.40443723\n",
      "Validation score: 0.875000\n",
      "Iteration 10, loss = 0.39167579\n",
      "Validation score: 0.875000\n",
      "Iteration 11, loss = 0.37549105\n",
      "Validation score: 0.843750\n",
      "Iteration 12, loss = 0.36779845\n",
      "Validation score: 0.781250\n",
      "Iteration 13, loss = 0.36163039\n",
      "Validation score: 0.843750\n",
      "Iteration 14, loss = 0.34963923\n",
      "Validation score: 0.812500\n",
      "Iteration 15, loss = 0.32858132\n",
      "Validation score: 0.781250\n",
      "Iteration 16, loss = 0.32352756\n",
      "Validation score: 0.843750\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.827, test=0.806) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68220742\n",
      "Validation score: 0.694444\n",
      "Iteration 2, loss = 0.61907614\n",
      "Validation score: 0.694444\n",
      "Iteration 3, loss = 0.57690639\n",
      "Validation score: 0.722222\n",
      "Iteration 4, loss = 0.52199667\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.47032902\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.43454130\n",
      "Validation score: 0.722222\n",
      "Iteration 7, loss = 0.41670787\n",
      "Validation score: 0.722222\n",
      "Iteration 8, loss = 0.40887057\n",
      "Validation score: 0.722222\n",
      "Iteration 9, loss = 0.40756745\n",
      "Validation score: 0.722222\n",
      "Iteration 10, loss = 0.39128157\n",
      "Validation score: 0.666667\n",
      "Iteration 11, loss = 0.37926339\n",
      "Validation score: 0.666667\n",
      "Iteration 12, loss = 0.37144332\n",
      "Validation score: 0.666667\n",
      "Iteration 13, loss = 0.35851632\n",
      "Validation score: 0.666667\n",
      "Iteration 14, loss = 0.35166481\n",
      "Validation score: 0.750000\n",
      "Iteration 15, loss = 0.34620489\n",
      "Validation score: 0.750000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.807, test=0.806) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68010643\n",
      "Validation score: 0.700000\n",
      "Iteration 2, loss = 0.61310142\n",
      "Validation score: 0.700000\n",
      "Iteration 3, loss = 0.57126644\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.52671147\n",
      "Validation score: 0.775000\n",
      "Iteration 5, loss = 0.47416602\n",
      "Validation score: 0.775000\n",
      "Iteration 6, loss = 0.44258719\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.43008803\n",
      "Validation score: 0.750000\n",
      "Iteration 8, loss = 0.41512833\n",
      "Validation score: 0.750000\n",
      "Iteration 9, loss = 0.40856586\n",
      "Validation score: 0.750000\n",
      "Iteration 10, loss = 0.40120473\n",
      "Validation score: 0.775000\n",
      "Iteration 11, loss = 0.38807973\n",
      "Validation score: 0.775000\n",
      "Iteration 12, loss = 0.37770462\n",
      "Validation score: 0.750000\n",
      "Iteration 13, loss = 0.36900364\n",
      "Validation score: 0.750000\n",
      "Iteration 14, loss = 0.36209251\n",
      "Validation score: 0.750000\n",
      "Iteration 15, loss = 0.35594007\n",
      "Validation score: 0.800000\n",
      "Iteration 16, loss = 0.34289032\n",
      "Validation score: 0.775000\n",
      "Iteration 17, loss = 0.33247293\n",
      "Validation score: 0.775000\n",
      "Iteration 18, loss = 0.32317706\n",
      "Validation score: 0.725000\n",
      "Iteration 19, loss = 0.32319917\n",
      "Validation score: 0.775000\n",
      "Iteration 20, loss = 0.30997708\n",
      "Validation score: 0.725000\n",
      "Iteration 21, loss = 0.29749940\n",
      "Validation score: 0.725000\n",
      "Iteration 22, loss = 0.29627080\n",
      "Validation score: 0.725000\n",
      "Iteration 23, loss = 0.28415435\n",
      "Validation score: 0.750000\n",
      "Iteration 24, loss = 0.27985168\n",
      "Validation score: 0.750000\n",
      "Iteration 25, loss = 0.26948139\n",
      "Validation score: 0.750000\n",
      "Iteration 26, loss = 0.26041977\n",
      "Validation score: 0.775000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.847, test=0.776) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68993306\n",
      "Validation score: 0.750000\n",
      "Iteration 2, loss = 0.65575795\n",
      "Validation score: 0.750000\n",
      "Iteration 3, loss = 0.61683135\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.57610738\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.53535932\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.49512037\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.45410018\n",
      "Validation score: 0.750000\n",
      "Iteration 8, loss = 0.41208851\n",
      "Validation score: 0.750000\n",
      "Iteration 9, loss = 0.36870907\n",
      "Validation score: 0.750000\n",
      "Iteration 10, loss = 0.32332562\n",
      "Validation score: 0.500000\n",
      "Iteration 11, loss = 0.27719161\n",
      "Validation score: 0.500000\n",
      "Iteration 12, loss = 0.23062006\n",
      "Validation score: 0.500000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.718, test=0.643) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.70164583\n",
      "Validation score: 0.875000\n",
      "Iteration 2, loss = 0.66845529\n",
      "Validation score: 0.750000\n",
      "Iteration 3, loss = 0.62812605\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.58389278\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.53809783\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.49199873\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.44642304\n",
      "Validation score: 0.875000\n",
      "Iteration 8, loss = 0.40362194\n",
      "Validation score: 0.875000\n",
      "Iteration 9, loss = 0.36717964\n",
      "Validation score: 0.875000\n",
      "Iteration 10, loss = 0.33770663\n",
      "Validation score: 0.875000\n",
      "Iteration 11, loss = 0.31441576\n",
      "Validation score: 0.875000\n",
      "Iteration 12, loss = 0.29410979\n",
      "Validation score: 0.875000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.679, test=0.663) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69453203\n",
      "Validation score: 0.750000\n",
      "Iteration 2, loss = 0.66288659\n",
      "Validation score: 0.750000\n",
      "Iteration 3, loss = 0.62834763\n",
      "Validation score: 0.666667\n",
      "Iteration 4, loss = 0.59446649\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.56127393\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.52791677\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.49429030\n",
      "Validation score: 0.916667\n",
      "Iteration 8, loss = 0.46115731\n",
      "Validation score: 0.916667\n",
      "Iteration 9, loss = 0.43031997\n",
      "Validation score: 0.916667\n",
      "Iteration 10, loss = 0.40358064\n",
      "Validation score: 0.916667\n",
      "Iteration 11, loss = 0.38162671\n",
      "Validation score: 0.833333\n",
      "Iteration 12, loss = 0.36378157\n",
      "Validation score: 0.833333\n",
      "Iteration 13, loss = 0.34906480\n",
      "Validation score: 0.833333\n",
      "Iteration 14, loss = 0.33607034\n",
      "Validation score: 0.833333\n",
      "Iteration 15, loss = 0.32368474\n",
      "Validation score: 0.833333\n",
      "Iteration 16, loss = 0.31134292\n",
      "Validation score: 0.833333\n",
      "Iteration 17, loss = 0.29941750\n",
      "Validation score: 0.916667\n",
      "Iteration 18, loss = 0.28745440\n",
      "Validation score: 0.916667\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  31 tasks      | elapsed:    1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................., score=(train=0.846, test=0.786) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69072277\n",
      "Validation score: 0.812500\n",
      "Iteration 2, loss = 0.65807601\n",
      "Validation score: 0.687500\n",
      "Iteration 3, loss = 0.62559969\n",
      "Validation score: 0.687500\n",
      "Iteration 4, loss = 0.59632319\n",
      "Validation score: 0.812500\n",
      "Iteration 5, loss = 0.56829446\n",
      "Validation score: 0.812500\n",
      "Iteration 6, loss = 0.53848828\n",
      "Validation score: 0.812500\n",
      "Iteration 7, loss = 0.50713672\n",
      "Validation score: 0.875000\n",
      "Iteration 8, loss = 0.47626191\n",
      "Validation score: 0.875000\n",
      "Iteration 9, loss = 0.44816414\n",
      "Validation score: 0.875000\n",
      "Iteration 10, loss = 0.42404816\n",
      "Validation score: 0.875000\n",
      "Iteration 11, loss = 0.40411395\n",
      "Validation score: 0.937500\n",
      "Iteration 12, loss = 0.38773601\n",
      "Validation score: 0.937500\n",
      "Iteration 13, loss = 0.37405535\n",
      "Validation score: 0.937500\n",
      "Iteration 14, loss = 0.36218556\n",
      "Validation score: 0.937500\n",
      "Iteration 15, loss = 0.35133753\n",
      "Validation score: 0.937500\n",
      "Iteration 16, loss = 0.34098640\n",
      "Validation score: 0.937500\n",
      "Iteration 17, loss = 0.33066682\n",
      "Validation score: 0.937500\n",
      "Iteration 18, loss = 0.32024362\n",
      "Validation score: 0.937500\n",
      "Iteration 19, loss = 0.30946485\n",
      "Validation score: 0.937500\n",
      "Iteration 20, loss = 0.29853109\n",
      "Validation score: 0.937500\n",
      "Iteration 21, loss = 0.28727151\n",
      "Validation score: 0.937500\n",
      "Iteration 22, loss = 0.27609102\n",
      "Validation score: 0.875000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.865, test=0.724) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69043530\n",
      "Validation score: 0.750000\n",
      "Iteration 2, loss = 0.65305361\n",
      "Validation score: 0.700000\n",
      "Iteration 3, loss = 0.61857538\n",
      "Validation score: 0.700000\n",
      "Iteration 4, loss = 0.59102362\n",
      "Validation score: 0.700000\n",
      "Iteration 5, loss = 0.56717647\n",
      "Validation score: 0.800000\n",
      "Iteration 6, loss = 0.54182070\n",
      "Validation score: 0.850000\n",
      "Iteration 7, loss = 0.51304455\n",
      "Validation score: 0.900000\n",
      "Iteration 8, loss = 0.48346849\n",
      "Validation score: 0.900000\n",
      "Iteration 9, loss = 0.45644633\n",
      "Validation score: 0.900000\n",
      "Iteration 10, loss = 0.43358531\n",
      "Validation score: 0.900000\n",
      "Iteration 11, loss = 0.41543233\n",
      "Validation score: 0.900000\n",
      "Iteration 12, loss = 0.40130180\n",
      "Validation score: 0.950000\n",
      "Iteration 13, loss = 0.39030851\n",
      "Validation score: 0.950000\n",
      "Iteration 14, loss = 0.38161137\n",
      "Validation score: 0.950000\n",
      "Iteration 15, loss = 0.37403803\n",
      "Validation score: 0.900000\n",
      "Iteration 16, loss = 0.36650588\n",
      "Validation score: 0.850000\n",
      "Iteration 17, loss = 0.35867041\n",
      "Validation score: 0.850000\n",
      "Iteration 18, loss = 0.35029080\n",
      "Validation score: 0.900000\n",
      "Iteration 19, loss = 0.34163612\n",
      "Validation score: 0.850000\n",
      "Iteration 20, loss = 0.33272962\n",
      "Validation score: 0.850000\n",
      "Iteration 21, loss = 0.32354594\n",
      "Validation score: 0.850000\n",
      "Iteration 22, loss = 0.31435101\n",
      "Validation score: 0.850000\n",
      "Iteration 23, loss = 0.30506338\n",
      "Validation score: 0.850000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.847, test=0.786) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68931857\n",
      "Validation score: 0.708333\n",
      "Iteration 2, loss = 0.62919506\n",
      "Validation score: 0.708333\n",
      "Iteration 3, loss = 0.58585650\n",
      "Validation score: 0.791667\n",
      "Iteration 4, loss = 0.55313531\n",
      "Validation score: 0.916667\n",
      "Iteration 5, loss = 0.50863115\n",
      "Validation score: 0.875000\n",
      "Iteration 6, loss = 0.47659608\n",
      "Validation score: 0.875000\n",
      "Iteration 7, loss = 0.45120386\n",
      "Validation score: 0.875000\n",
      "Iteration 8, loss = 0.43374927\n",
      "Validation score: 0.916667\n",
      "Iteration 9, loss = 0.42378533\n",
      "Validation score: 0.916667\n",
      "Iteration 10, loss = 0.46313387\n",
      "Validation score: 0.958333\n",
      "Iteration 11, loss = 0.45651016\n",
      "Validation score: 0.958333\n",
      "Iteration 12, loss = 0.46819435\n",
      "Validation score: 0.958333\n",
      "Iteration 13, loss = 0.45674904\n",
      "Validation score: 0.958333\n",
      "Iteration 14, loss = 0.48198954\n",
      "Validation score: 0.916667\n",
      "Iteration 15, loss = 0.47105252\n",
      "Validation score: 0.875000\n",
      "Iteration 16, loss = 0.44307417\n",
      "Validation score: 0.875000\n",
      "Iteration 17, loss = 0.40855695\n",
      "Validation score: 0.875000\n",
      "Iteration 18, loss = 0.45530121\n",
      "Validation score: 0.875000\n",
      "Iteration 19, loss = 0.43075014\n",
      "Validation score: 0.916667\n",
      "Iteration 20, loss = 0.40819814\n",
      "Validation score: 0.875000\n",
      "Iteration 21, loss = 0.39481476\n",
      "Validation score: 0.833333\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.834, test=0.786) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68859818\n",
      "Validation score: 0.678571\n",
      "Iteration 2, loss = 0.61633484\n",
      "Validation score: 0.678571\n",
      "Iteration 3, loss = 0.58426030\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.53915363\n",
      "Validation score: 0.857143\n",
      "Iteration 5, loss = 0.47697145\n",
      "Validation score: 0.857143\n",
      "Iteration 6, loss = 0.44542175\n",
      "Validation score: 0.857143\n",
      "Iteration 7, loss = 0.42956712\n",
      "Validation score: 0.857143\n",
      "Iteration 8, loss = 0.42305806\n",
      "Validation score: 0.821429\n",
      "Iteration 9, loss = 0.39803703\n",
      "Validation score: 0.785714\n",
      "Iteration 10, loss = 0.40688328\n",
      "Validation score: 0.821429\n",
      "Iteration 11, loss = 0.38259258\n",
      "Validation score: 0.821429\n",
      "Iteration 12, loss = 0.37287497\n",
      "Validation score: 0.821429\n",
      "Iteration 13, loss = 0.36272436\n",
      "Validation score: 0.714286\n",
      "Iteration 14, loss = 0.38449204\n",
      "Validation score: 0.857143\n",
      "Iteration 15, loss = 0.38106030\n",
      "Validation score: 0.785714\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.825, test=0.776) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68989333\n",
      "Validation score: 0.687500\n",
      "Iteration 2, loss = 0.62203798\n",
      "Validation score: 0.687500\n",
      "Iteration 3, loss = 0.57348508\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.52920153\n",
      "Validation score: 0.906250\n",
      "Iteration 5, loss = 0.48033899\n",
      "Validation score: 0.906250\n",
      "Iteration 6, loss = 0.44311960\n",
      "Validation score: 0.906250\n",
      "Iteration 7, loss = 0.42727126\n",
      "Validation score: 0.906250\n",
      "Iteration 8, loss = 0.42094838\n",
      "Validation score: 0.906250\n",
      "Iteration 9, loss = 0.41332936\n",
      "Validation score: 0.906250\n",
      "Iteration 10, loss = 0.40423102\n",
      "Validation score: 0.906250\n",
      "Iteration 11, loss = 0.39364150\n",
      "Validation score: 0.906250\n",
      "Iteration 12, loss = 0.38555366\n",
      "Validation score: 0.906250\n",
      "Iteration 13, loss = 0.37993244\n",
      "Validation score: 0.875000\n",
      "Iteration 14, loss = 0.37487151\n",
      "Validation score: 0.875000\n",
      "Iteration 15, loss = 0.35673393\n",
      "Validation score: 0.875000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.831, test=0.776) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68466554\n",
      "Validation score: 0.694444\n",
      "Iteration 2, loss = 0.62697170\n",
      "Validation score: 0.694444\n",
      "Iteration 3, loss = 0.58578209\n",
      "Validation score: 0.777778\n",
      "Iteration 4, loss = 0.53431353\n",
      "Validation score: 0.861111\n",
      "Iteration 5, loss = 0.48528666\n",
      "Validation score: 0.861111\n",
      "Iteration 6, loss = 0.45494582\n",
      "Validation score: 0.861111\n",
      "Iteration 7, loss = 0.43856558\n",
      "Validation score: 0.861111\n",
      "Iteration 8, loss = 0.43135861\n",
      "Validation score: 0.861111\n",
      "Iteration 9, loss = 0.43734733\n",
      "Validation score: 0.861111\n",
      "Iteration 10, loss = 0.42638084\n",
      "Validation score: 0.861111\n",
      "Iteration 11, loss = 0.41704352\n",
      "Validation score: 0.861111\n",
      "Iteration 12, loss = 0.40308105\n",
      "Validation score: 0.833333\n",
      "Iteration 13, loss = 0.39357821\n",
      "Validation score: 0.833333\n",
      "Iteration 14, loss = 0.38910990\n",
      "Validation score: 0.861111\n",
      "Iteration 15, loss = 0.38022935\n",
      "Validation score: 0.861111\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.818, test=0.786) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68188544\n",
      "Validation score: 0.700000\n",
      "Iteration 2, loss = 0.61810844\n",
      "Validation score: 0.700000\n",
      "Iteration 3, loss = 0.57890995\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.53950852\n",
      "Validation score: 0.875000\n",
      "Iteration 5, loss = 0.49336679\n",
      "Validation score: 0.900000\n",
      "Iteration 6, loss = 0.46191393\n",
      "Validation score: 0.875000\n",
      "Iteration 7, loss = 0.44999917\n",
      "Validation score: 0.875000\n",
      "Iteration 8, loss = 0.43618764\n",
      "Validation score: 0.900000\n",
      "Iteration 9, loss = 0.43317749\n",
      "Validation score: 0.900000\n",
      "Iteration 10, loss = 0.43193398\n",
      "Validation score: 0.900000\n",
      "Iteration 11, loss = 0.41726785\n",
      "Validation score: 0.900000\n",
      "Iteration 12, loss = 0.40604039\n",
      "Validation score: 0.900000\n",
      "Iteration 13, loss = 0.39852491\n",
      "Validation score: 0.900000\n",
      "Iteration 14, loss = 0.39258899\n",
      "Validation score: 0.875000\n",
      "Iteration 15, loss = 0.38712324\n",
      "Validation score: 0.900000\n",
      "Iteration 16, loss = 0.37704120\n",
      "Validation score: 0.900000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.827, test=0.796) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68993306\n",
      "Validation score: 0.750000\n",
      "Iteration 2, loss = 0.65575795\n",
      "Validation score: 0.750000\n",
      "Iteration 3, loss = 0.61683135\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.57610738\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.53535932\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.49512037\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.45410018\n",
      "Validation score: 0.750000\n",
      "Iteration 8, loss = 0.41208851\n",
      "Validation score: 0.750000\n",
      "Iteration 9, loss = 0.36870907\n",
      "Validation score: 0.750000\n",
      "Iteration 10, loss = 0.32332562\n",
      "Validation score: 0.500000\n",
      "Iteration 11, loss = 0.27719161\n",
      "Validation score: 0.500000\n",
      "Iteration 12, loss = 0.23062006\n",
      "Validation score: 0.500000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.718, test=0.602) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.70164583\n",
      "Validation score: 0.875000\n",
      "Iteration 2, loss = 0.66845529\n",
      "Validation score: 0.750000\n",
      "Iteration 3, loss = 0.62812605\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.58389278\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.53809783\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.49199873\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.44642304\n",
      "Validation score: 0.875000\n",
      "Iteration 8, loss = 0.40362194\n",
      "Validation score: 0.875000\n",
      "Iteration 9, loss = 0.36717964\n",
      "Validation score: 0.875000\n",
      "Iteration 10, loss = 0.33770663\n",
      "Validation score: 0.875000\n",
      "Iteration 11, loss = 0.31441576\n",
      "Validation score: 0.875000\n",
      "Iteration 12, loss = 0.29410979\n",
      "Validation score: 0.875000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.679, test=0.643) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69453203\n",
      "Validation score: 0.750000\n",
      "Iteration 2, loss = 0.66288659\n",
      "Validation score: 0.750000\n",
      "Iteration 3, loss = 0.62834763\n",
      "Validation score: 0.666667\n",
      "Iteration 4, loss = 0.59446649\n",
      "Validation score: 0.750000\n",
      "Iteration 5, loss = 0.56127393\n",
      "Validation score: 0.750000\n",
      "Iteration 6, loss = 0.52791677\n",
      "Validation score: 0.750000\n",
      "Iteration 7, loss = 0.49429030\n",
      "Validation score: 0.916667\n",
      "Iteration 8, loss = 0.46115731\n",
      "Validation score: 0.916667\n",
      "Iteration 9, loss = 0.43031997\n",
      "Validation score: 0.916667\n",
      "Iteration 10, loss = 0.40358064\n",
      "Validation score: 0.916667\n",
      "Iteration 11, loss = 0.38162671\n",
      "Validation score: 0.833333\n",
      "Iteration 12, loss = 0.36378157\n",
      "Validation score: 0.833333\n",
      "Iteration 13, loss = 0.34906480\n",
      "Validation score: 0.833333\n",
      "Iteration 14, loss = 0.33607034\n",
      "Validation score: 0.833333\n",
      "Iteration 15, loss = 0.32368474\n",
      "Validation score: 0.833333\n",
      "Iteration 16, loss = 0.31134292\n",
      "Validation score: 0.833333\n",
      "Iteration 17, loss = 0.29941750\n",
      "Validation score: 0.916667\n",
      "Iteration 18, loss = 0.28745440\n",
      "Validation score: 0.916667\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.846, test=0.745) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69072277\n",
      "Validation score: 0.812500\n",
      "Iteration 2, loss = 0.65807601\n",
      "Validation score: 0.687500\n",
      "Iteration 3, loss = 0.62559969\n",
      "Validation score: 0.687500\n",
      "Iteration 4, loss = 0.59632319\n",
      "Validation score: 0.812500\n",
      "Iteration 5, loss = 0.56829446\n",
      "Validation score: 0.812500\n",
      "Iteration 6, loss = 0.53848828\n",
      "Validation score: 0.812500\n",
      "Iteration 7, loss = 0.50713672\n",
      "Validation score: 0.875000\n",
      "Iteration 8, loss = 0.47626191\n",
      "Validation score: 0.875000\n",
      "Iteration 9, loss = 0.44816414\n",
      "Validation score: 0.875000\n",
      "Iteration 10, loss = 0.42404816\n",
      "Validation score: 0.875000\n",
      "Iteration 11, loss = 0.40411395\n",
      "Validation score: 0.937500\n",
      "Iteration 12, loss = 0.38773601\n",
      "Validation score: 0.937500\n",
      "Iteration 13, loss = 0.37405535\n",
      "Validation score: 0.937500\n",
      "Iteration 14, loss = 0.36218556\n",
      "Validation score: 0.937500\n",
      "Iteration 15, loss = 0.35133753\n",
      "Validation score: 0.937500\n",
      "Iteration 16, loss = 0.34098640\n",
      "Validation score: 0.937500\n",
      "Iteration 17, loss = 0.33066682\n",
      "Validation score: 0.937500\n",
      "Iteration 18, loss = 0.32024362\n",
      "Validation score: 0.937500\n",
      "Iteration 19, loss = 0.30946485\n",
      "Validation score: 0.937500\n",
      "Iteration 20, loss = 0.29853109\n",
      "Validation score: 0.937500\n",
      "Iteration 21, loss = 0.28727151\n",
      "Validation score: 0.937500\n",
      "Iteration 22, loss = 0.27609102\n",
      "Validation score: 0.875000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.865, test=0.776) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.69043530\n",
      "Validation score: 0.750000\n",
      "Iteration 2, loss = 0.65305361\n",
      "Validation score: 0.700000\n",
      "Iteration 3, loss = 0.61857538\n",
      "Validation score: 0.700000\n",
      "Iteration 4, loss = 0.59102362\n",
      "Validation score: 0.700000\n",
      "Iteration 5, loss = 0.56717647\n",
      "Validation score: 0.800000\n",
      "Iteration 6, loss = 0.54182070\n",
      "Validation score: 0.850000\n",
      "Iteration 7, loss = 0.51304455\n",
      "Validation score: 0.900000\n",
      "Iteration 8, loss = 0.48346849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.900000\n",
      "Iteration 9, loss = 0.45644633\n",
      "Validation score: 0.900000\n",
      "Iteration 10, loss = 0.43358531\n",
      "Validation score: 0.900000\n",
      "Iteration 11, loss = 0.41543233\n",
      "Validation score: 0.900000\n",
      "Iteration 12, loss = 0.40130180\n",
      "Validation score: 0.950000\n",
      "Iteration 13, loss = 0.39030851\n",
      "Validation score: 0.950000\n",
      "Iteration 14, loss = 0.38161137\n",
      "Validation score: 0.950000\n",
      "Iteration 15, loss = 0.37403803\n",
      "Validation score: 0.900000\n",
      "Iteration 16, loss = 0.36650588\n",
      "Validation score: 0.850000\n",
      "Iteration 17, loss = 0.35867041\n",
      "Validation score: 0.850000\n",
      "Iteration 18, loss = 0.35029080\n",
      "Validation score: 0.900000\n",
      "Iteration 19, loss = 0.34163612\n",
      "Validation score: 0.850000\n",
      "Iteration 20, loss = 0.33272962\n",
      "Validation score: 0.850000\n",
      "Iteration 21, loss = 0.32354594\n",
      "Validation score: 0.850000\n",
      "Iteration 22, loss = 0.31435101\n",
      "Validation score: 0.850000\n",
      "Iteration 23, loss = 0.30506338\n",
      "Validation score: 0.850000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.847, test=0.816) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68931857\n",
      "Validation score: 0.708333\n",
      "Iteration 2, loss = 0.62919506\n",
      "Validation score: 0.708333\n",
      "Iteration 3, loss = 0.58585650\n",
      "Validation score: 0.791667\n",
      "Iteration 4, loss = 0.55313531\n",
      "Validation score: 0.916667\n",
      "Iteration 5, loss = 0.50863115\n",
      "Validation score: 0.875000\n",
      "Iteration 6, loss = 0.47659608\n",
      "Validation score: 0.875000\n",
      "Iteration 7, loss = 0.45120386\n",
      "Validation score: 0.875000\n",
      "Iteration 8, loss = 0.43374927\n",
      "Validation score: 0.916667\n",
      "Iteration 9, loss = 0.42378533\n",
      "Validation score: 0.916667\n",
      "Iteration 10, loss = 0.46313387\n",
      "Validation score: 0.958333\n",
      "Iteration 11, loss = 0.45651016\n",
      "Validation score: 0.958333\n",
      "Iteration 12, loss = 0.46819435\n",
      "Validation score: 0.958333\n",
      "Iteration 13, loss = 0.45674904\n",
      "Validation score: 0.958333\n",
      "Iteration 14, loss = 0.48198954\n",
      "Validation score: 0.916667\n",
      "Iteration 15, loss = 0.47105252\n",
      "Validation score: 0.875000\n",
      "Iteration 16, loss = 0.44307417\n",
      "Validation score: 0.875000\n",
      "Iteration 17, loss = 0.40855695\n",
      "Validation score: 0.875000\n",
      "Iteration 18, loss = 0.45530121\n",
      "Validation score: 0.875000\n",
      "Iteration 19, loss = 0.43075014\n",
      "Validation score: 0.916667\n",
      "Iteration 20, loss = 0.40819814\n",
      "Validation score: 0.875000\n",
      "Iteration 21, loss = 0.39481476\n",
      "Validation score: 0.833333\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.834, test=0.816) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68859818\n",
      "Validation score: 0.678571\n",
      "Iteration 2, loss = 0.61633484\n",
      "Validation score: 0.678571\n",
      "Iteration 3, loss = 0.58426030\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.53915363\n",
      "Validation score: 0.857143\n",
      "Iteration 5, loss = 0.47697145\n",
      "Validation score: 0.857143\n",
      "Iteration 6, loss = 0.44542175\n",
      "Validation score: 0.857143\n",
      "Iteration 7, loss = 0.42956712\n",
      "Validation score: 0.857143\n",
      "Iteration 8, loss = 0.42305806\n",
      "Validation score: 0.821429\n",
      "Iteration 9, loss = 0.39803703\n",
      "Validation score: 0.785714\n",
      "Iteration 10, loss = 0.40688328\n",
      "Validation score: 0.821429\n",
      "Iteration 11, loss = 0.38259258\n",
      "Validation score: 0.821429\n",
      "Iteration 12, loss = 0.37287497\n",
      "Validation score: 0.821429\n",
      "Iteration 13, loss = 0.36272436\n",
      "Validation score: 0.714286\n",
      "Iteration 14, loss = 0.38449204\n",
      "Validation score: 0.857143\n",
      "Iteration 15, loss = 0.38106030\n",
      "Validation score: 0.785714\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.825, test=0.796) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68692376\n",
      "Validation score: 0.687500\n",
      "Iteration 2, loss = 0.62115685\n",
      "Validation score: 0.687500\n",
      "Iteration 3, loss = 0.57720691\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.54101004\n",
      "Validation score: 0.906250\n",
      "Iteration 5, loss = 0.49888930\n",
      "Validation score: 0.906250\n",
      "Iteration 6, loss = 0.46473746\n",
      "Validation score: 0.906250\n",
      "Iteration 7, loss = 0.45042992\n",
      "Validation score: 0.906250\n",
      "Iteration 8, loss = 0.44478102\n",
      "Validation score: 0.906250\n",
      "Iteration 9, loss = 0.43528639\n",
      "Validation score: 0.906250\n",
      "Iteration 10, loss = 0.42388388\n",
      "Validation score: 0.906250\n",
      "Iteration 11, loss = 0.41271650\n",
      "Validation score: 0.906250\n",
      "Iteration 12, loss = 0.40328691\n",
      "Validation score: 0.906250\n",
      "Iteration 13, loss = 0.39636849\n",
      "Validation score: 0.812500\n",
      "Iteration 14, loss = 0.39368828\n",
      "Validation score: 0.875000\n",
      "Iteration 15, loss = 0.37428875\n",
      "Validation score: 0.875000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.815, test=0.796) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.67791501\n",
      "Validation score: 0.694444\n",
      "Iteration 2, loss = 0.61541439\n",
      "Validation score: 0.694444\n",
      "Iteration 3, loss = 0.58534602\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.54157592\n",
      "Validation score: 0.861111\n",
      "Iteration 5, loss = 0.49896237\n",
      "Validation score: 0.861111\n",
      "Iteration 6, loss = 0.47118242\n",
      "Validation score: 0.888889\n",
      "Iteration 7, loss = 0.45721146\n",
      "Validation score: 0.888889\n",
      "Iteration 8, loss = 0.45121698\n",
      "Validation score: 0.888889\n",
      "Iteration 9, loss = 0.44525390\n",
      "Validation score: 0.888889\n",
      "Iteration 10, loss = 0.43321510\n",
      "Validation score: 0.888889\n",
      "Iteration 11, loss = 0.42227591\n",
      "Validation score: 0.888889\n",
      "Iteration 12, loss = 0.41174154\n",
      "Validation score: 0.888889\n",
      "Iteration 13, loss = 0.40370891\n",
      "Validation score: 0.861111\n",
      "Iteration 14, loss = 0.39483195\n",
      "Validation score: 0.861111\n",
      "Iteration 15, loss = 0.38721861\n",
      "Validation score: 0.833333\n",
      "Iteration 16, loss = 0.37920774\n",
      "Validation score: 0.861111\n",
      "Iteration 17, loss = 0.37030524\n",
      "Validation score: 0.861111\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.815, test=0.816) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "Iteration 1, loss = 0.68002842\n",
      "Validation score: 0.700000\n",
      "Iteration 2, loss = 0.61482380\n",
      "Validation score: 0.700000\n",
      "Iteration 3, loss = 0.57779739\n",
      "Validation score: 0.750000\n",
      "Iteration 4, loss = 0.53766705\n",
      "Validation score: 0.875000\n",
      "Iteration 5, loss = 0.49318175\n",
      "Validation score: 0.900000\n",
      "Iteration 6, loss = 0.46603676\n",
      "Validation score: 0.875000\n",
      "Iteration 7, loss = 0.45193767\n",
      "Validation score: 0.875000\n",
      "Iteration 8, loss = 0.44347951\n",
      "Validation score: 0.900000\n",
      "Iteration 9, loss = 0.43892584\n",
      "Validation score: 0.900000\n",
      "Iteration 10, loss = 0.43607436\n",
      "Validation score: 0.900000\n",
      "Iteration 11, loss = 0.42346864\n",
      "Validation score: 0.900000\n",
      "Iteration 12, loss = 0.41366708\n",
      "Validation score: 0.900000\n",
      "Iteration 13, loss = 0.40640961\n",
      "Validation score: 0.900000\n",
      "Iteration 14, loss = 0.39867669\n",
      "Validation score: 0.900000\n",
      "Iteration 15, loss = 0.39443841\n",
      "Validation score: 0.900000\n",
      "Iteration 16, loss = 0.38499511\n",
      "Validation score: 0.900000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "[CV] END ..................., score=(train=0.824, test=0.816) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.5s\n"
     ]
    }
   ],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    best_clf, X_train, Y_train, cv=5, train_sizes=np.linspace(0.1, 1.0, 10), scoring='accuracy', verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0e9868a0-637e-4016-86db-6a5342dbfbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "51fcdbcf-0fdf-483c-8483-cb7807034f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training Accuracy')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.15, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='Validation Accuracy')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.15, color='green')\n",
    "\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b50ffdac-c46b-419d-b5fc-ae5f37727937",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Fit the model\n",
    "nb_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = nb_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "3c67295d-791b-45bd-ad9f-024b2e30807e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.7804878048780488\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.42      0.57        43\n",
      "         1.0       0.76      0.97      0.85        80\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.83      0.70      0.71       123\n",
      "weighted avg       0.81      0.78      0.75       123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Naive Bayes Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad1db7-dd11-48af-a79b-66052fe5c8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
